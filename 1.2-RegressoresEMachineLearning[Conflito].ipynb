{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressores & Aprendizagem de Máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML como um problema de otimização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Estimador linear_, considerando $n-1$ atributos: \n",
    "    \n",
    "    $\\hat{y}(\\textbf{w}) = \\hat{y}(\\textbf{w}, \\textbf{x}) = w_0 x_0 + w_1 x_1 + \\ldots + w_{n-1} x_{n-1} + b$\n",
    "    \n",
    "    $\\hat{y}(\\textbf{w}) = w_0 x_0 + w_1 x_1 + \\ldots + w_{n-1} x_{n-1} + w_{n} x_{n}$ (bias incorporado em $\\textbf{x}$, $b = w_n, x_n = 1$)\n",
    "    \n",
    "    $\\hat{y}(\\textbf{w}) = \\textbf{x} \\dot~\\textbf{w}$\n",
    "\n",
    "    Se considerarmos todas as $m$ instâncias $\\textbf{x}$, temos $\\hat{y}(\\textbf{w}) = X \\dot~\\textbf{w}$ (supondo $X^{(m \\times n)}$ e $\\textbf{w}^{(n \\times 1)}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Eventualmente estimador linear poderia incorporar um transformador, uma _função de ativação_ $\\alpha$: \n",
    "    \n",
    "    $\\hat{y}(\\textbf{w}) = \\alpha(X \\dot~\\textbf{w})$\n",
    "    \n",
    "    Supondo $\\alpha(x) = x$, função identidade, temos o estimador clássico usado na regressão linear, ou seja,     $\\hat{y}(\\textbf{w}) = X \\dot~\\textbf{w}$. Funções de ativação podem ser usadas para transformar a saída para um certo intervalo (-1 a 1, 0 a 1, etc) e também modificarem a natureza simples de um estimador polinomial de grau 1, como o usado aqui. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Função de perda_ (_loss_), avalia o quão bom é o seu estimador $\\hat{y}(\\textbf{w})$ em relação aos valores reais $\\textbf{y}$. Por exemplo, ao adotarmos a média das diferenças dos quadrados (MSE -- mean squared error), temos:\n",
    "\n",
    "    $\\ell(\\hat{y}(\\textbf{w}), \\textbf{y}) = \\frac{1}{m} \\sum_{i}^{m}{(\\hat{y}_i(\\textbf{w}) - y_i)^2}$\n",
    "    \n",
    "    $\\ell(\\hat{y}(\\textbf{w}), \\textbf{y}) = mean ((\\hat{y}(\\textbf{w}) - \\textbf{y})^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Função de perda com _regularizador_ $R$:\n",
    "\n",
    "    $L(\\hat{y}(\\textbf{w}), \\textbf{y}) = \\ell(\\hat{y}(\\textbf{w}), \\textbf{y}) + \\lambda R(\\textbf{w})$\n",
    "    \n",
    "    O regularizador é uma função de penalização que tem por objetivo eliminar certos conjuntos de pesos, privilegiando outros. Ao fazer isso, o modelo se restringe a um menor espaço de pesos, melhorando sua generalização. Exemplos de regularizadores são o L1 ($R(\\mathbf{w}) \\approx \\sum_{\\forall i}{|w_i|}$) e o L2 ($R(\\mathbf{w}) \\approx \\sum_{\\forall i}{|w_i|}^2$). Note que enquanto L1 prefere pesos não nulos, o L2 não gosta de _outliers_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Objetivo de ML é determinar $\\textbf{w}$ que minimiza $L$, ou seja, determinar $\\textbf{w}$ tal que $\\frac{\\partial}{\\partial \\textbf{w}} L(\\hat{y}(\\textbf{w}), \\textbf{y}) = 0$. No nosso caso, supondo $\\lambda = 0$:\n",
    "\n",
    "    $\n",
    "    \\begin{align}\n",
    "        \\frac{\\partial}{\\partial \\textbf{w}} L(\\hat{y}(\\textbf{w}), \\textbf{y}) &= \\frac{\\partial}{\\partial \\textbf{w}} \\frac{1}{m} \\sum_{i}^{m}{(\\hat{y}_i(\\textbf{w}) - y_i)^2} = 0 \\\\\n",
    "        &= \\frac{1}{m} \\sum_{i}^{m}{\\frac{\\partial}{\\partial \\textbf{w}} (\\hat{y}_i(\\textbf{w}) - y_i)^2} \\\\\n",
    "        &= \\frac{1}{m} \\sum_{i}^{m}{\\frac{\\partial}{\\partial \\textbf{w}} (\\textbf{x}_i \\dot~\\textbf{w} - y_i)^2} \\\\\n",
    "        &= \\frac{1}{m} \\sum_{i}^{m}{\\frac{\\partial}{\\partial \\textbf{w}} ({\\textbf{x}_i}^2 \\dot~\\textbf{w}^2 - 2 \\textbf{x}_i \\dot~\\textbf{w} \\dot~y_i + {y_i}^2})  \\\\\n",
    "        &= \\frac{1}{m} \\sum_{i}^{m}{(2 {\\textbf{x}_i}^2 \\dot~\\textbf{w} - 2 \\textbf{x}_i \\dot~y_i)}  \\\\\n",
    "        &= \\frac{2}{m} \\sum_{i}^{m}{({\\textbf{x}_i}^2 \\dot~\\textbf{w} - \\textbf{x}_i \\dot~y_i)}  \\\\\n",
    "        &= \\frac{2}{m} (\\sum_{i}^{m}{{\\textbf{x}_i}^2 \\dot~\\textbf{w}} - \\sum_{i}^{m} {\\textbf{x}_i \\dot~y_i})  \\\\\n",
    "        &= \\frac{2}{m} (X^T X\\dot~\\textbf{w} - X^T \\textbf{y}) \\text{ supondo } X^{(m \\times n)}, \\textbf{y}^{(m \\times 1)} \\text{ e } \\textbf{w}^{(n \\times 1)}\\\\ \n",
    "        &= \\frac{2}{m} X^T (X\\dot~\\textbf{w} - \\textbf{y})  \n",
    "    \\end{align}    \n",
    "    $\n",
    "\n",
    "    Esta função corresponde ao gradiente da função de perda $L$ e pode ser usado para obter $\\textbf{w}$ tanto diretamente quanto iterativamente. Como a solução direta é limitada a valores pequenos de $n$ e $m$, vamos implementar a solução iterativa, o _Gradiente Descendente_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradiente Descendente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GradientDescendente($X^{m \\times n}$, $\\textbf{y}^{m \\times 1}$, taxa de aprendizado $\\eta$, número de épocas $N$):\n",
    "    - inicie $\\textbf{w}^{n \\times 1}$ com valores aleatorios entre -1 e 1\n",
    "    - para $N$ épocas:\n",
    "        - $\\hat{y}(\\textbf{w}) = X \\dot~\\textbf{w}$\n",
    "        - $\\ell(\\hat{y}(\\textbf{w}), \\textbf{y}) = mean ((\\hat{y}(\\textbf{w}) - \\textbf{y})^2)$\n",
    "        - $\\nabla\\ell = \\frac{2}{m} X^T (X\\dot~\\textbf{w} - ~\\textbf{y})$\n",
    "        - $\\textbf{w}' = \\textbf{w} - \\eta \\nabla\\ell$\n",
    "        - $\\textbf{w} = \\textbf{w}'$\n",
    "    - retorne $\\textbf{w}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GD em Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.         -0.77777778 -0.55555556 -0.33333333 -0.11111111  0.11111111\n",
      "  0.33333333  0.55555556  0.77777778  1.        ]\n",
      "[-8.65031837 -4.81077567 -3.4490515  -4.8064985  -2.17478898  0.05272406\n",
      "  0.44393123  1.74723462  1.96466113  4.43672087]\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(-1, 1, 10)\n",
    "y = 6. * x - 1.\n",
    "y += np.random.normal(0, 1.0, len(x))\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c6c9b79940>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c6c7017668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y, '.')\n",
    "plt.plot(6. * x - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xscaled = (x - np.mean(x))/np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.5666989 , -1.21854359, -0.87038828, -0.52223297, -0.17407766,\n",
       "        0.17407766,  0.52223297,  0.87038828,  1.21854359,  1.5666989 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorporando bias em X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.stack([np.ones(len(y)), xscaled]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -1.5666989 ],\n",
       "       [ 1.        , -1.21854359],\n",
       "       [ 1.        , -0.87038828],\n",
       "       [ 1.        , -0.52223297],\n",
       "       [ 1.        , -0.17407766],\n",
       "       [ 1.        ,  0.17407766],\n",
       "       [ 1.        ,  0.52223297],\n",
       "       [ 1.        ,  0.87038828],\n",
       "       [ 1.        ,  1.21854359],\n",
       "       [ 1.        ,  1.5666989 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.65031837],\n",
       "       [-4.81077567],\n",
       "       [-3.4490515 ],\n",
       "       [-4.8064985 ],\n",
       "       [-2.17478898],\n",
       "       [ 0.05272406],\n",
       "       [ 0.44393123],\n",
       "       [ 1.74723462],\n",
       "       [ 1.96466113],\n",
       "       [ 4.43672087]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n = X.shape\n",
    "m, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02585676],\n",
       "       [-0.59782556]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.random.uniform(-1, 1, (2,1))\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.68340522],\n",
       "       [ 1.4744723 ],\n",
       "       [ 1.26553938],\n",
       "       [ 1.05660646],\n",
       "       [ 0.84767354],\n",
       "       [ 0.63874063],\n",
       "       [ 0.42980771],\n",
       "       [ 0.22087479],\n",
       "       [ 0.01194187],\n",
       "       [-0.19699105]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(X, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gd(X, y, n_epochs = 100, lrating = 0.1):    \n",
    "    m, n = X.shape # m instancias e n colunas (incluindo bias)\n",
    "    Y = y.reshape(-1,1)\n",
    "    W = np.random.uniform(-1, 1, (n, 1))\n",
    "    for e in range(n_epochs):\n",
    "        Yhat = np.matmul(X, W)\n",
    "        error = Yhat - Y\n",
    "        loss = np.mean(error ** 2)\n",
    "        gloss = (2./m) * np.matmul(X.T, error)\n",
    "        Wn = W - lrating * gloss\n",
    "        W = Wn\n",
    "        if e%10 == 0:\n",
    "            print(loss)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.34341603039561\n",
      "0.42091357749818065\n",
      "0.22581040760110543\n",
      "0.22356102119919236\n",
      "0.223535087539643\n",
      "0.22353478854490522\n",
      "0.2235347850977305\n",
      "0.22353478505798727\n",
      "0.2235347850575291\n",
      "0.22353478505752383\n",
      "0.22353478505752378\n",
      "0.22353478505752372\n",
      "0.22353478505752383\n",
      "0.22353478505752378\n",
      "0.22353478505752372\n",
      "0.22353478505752372\n",
      "0.22353478505752372\n",
      "0.22353478505752378\n",
      "0.22353478505752378\n",
      "0.22353478505752378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.88848956],\n",
       "       [ 3.80333204]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = gd(X, y, n_epochs = 200, lrating = 0.1)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD8CAYAAACSCdTiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bdd7d68ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y, '.')\n",
    "plt.plot(np.matmul(X,W))\n",
    "plt.xlim(-1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traduzindo para TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gdtf(X, y, n_epochs = 100, lrating = 0.1):\n",
    "    m, n = X.shape\n",
    "    \n",
    "    X = tf.constant(X, dtype = tf.float32, name = \"X\")\n",
    "    y = tf.constant(y.reshape(-1, 1), dtype = tf.float32, name = \"y\")\n",
    "    W = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), name = \"W\")\n",
    "    \n",
    "    Yhat = tf.matmul(X, W, name = \"predictions\")\n",
    "    error = Yhat - y\n",
    "    loss = tf.reduce_mean(tf.square(error), name = \"loss\")\n",
    "    gloss = (2./m) * tf.matmul(tf.transpose(X), error)\n",
    "    training = tf.assign(W, W - lrating * gloss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as s:\n",
    "        s.run(init)\n",
    "        for e in range(n_epochs):\n",
    "            s.run(training)\n",
    "            if e%10==0:\n",
    "                print(loss.eval())\n",
    "        finalW = W.eval()\n",
    "        tf.summary.FileWriter('logs/tfhelloworld', s.graph)\n",
    "    return finalW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.816907\n",
      "0.95846015\n",
      "0.8678585\n",
      "0.86681384\n",
      "0.86680174\n",
      "0.86680174\n",
      "0.86680174\n",
      "0.86680144\n",
      "0.86680144\n",
      "0.86680144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.524616 ],\n",
       "       [ 3.6412103]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = gdtf(X, y, n_epochs=100)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-10, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8VOXZ//HPlQQQcWFxQXYQBBVF\nScRYVxAQEMUqKq3Fvah169Onta0+tbXtr9WqT+vuo4JFRau1LmhxX2pbi5KwKCgIskgEBAKyLxly\n/f64Z8xMmEBIcjIh832/Xnkxc86ZyZ15Ad/c17nPdczdERERScjJ9ABERKRhUTCIiEgKBYOIiKRQ\nMIiISAoFg4iIpFAwiIhIijoJBjMbZ2bLzWxm0rbWZvaGmc2N/9mqitdeFD9mrpldVBfjERGRmqur\nGcOfgSGVtv0MeMvdewBvxZ+nMLPWwC+BY4F+wC+rChAREakfdRIM7v4esKrS5hHA+Pjj8cBZaV56\nGvCGu69y99XAG2wfMCIiUo/yInzvA919KYC7LzWzA9Ic0x5YnPS8JL5tO2Y2BhgD0KJFi/xevXrV\n8XBFRBq34uLile6+/86OizIYqsPSbEvbo8PdHwIeAigoKPCioqIoxyUi0uiY2aLqHBflqqSvzOyg\n+GAOApanOaYE6Jj0vAOwJMIxiYjITkQZDBOBxCqji4AX0xzzGjDYzFrFTzoPjm8TEZEMqavlqk8B\n/wF6mlmJmV0G3AoMMrO5wKD4c8yswMweAXD3VcBvgCnxr1/Ht4mISIbY7th2W+cYRER2nZkVu3vB\nzo7Tlc8iIpJCwSAiIikUDCIikkLBICIiKRQMIiKSQsEgIiIpFAwiIpJCwSAiIikUDCIikkLBICIi\nKRQMIiKSQsEgIiIpFAwiIpJCwSAiIikUDCIikkLBICIiKRQMIiKSQsEgIiIpIg0GM+tpZtOTvtaa\n2Q8rHXOKma1JOubmKMckIiI7lhflm7v7HOAoADPLBb4Enk9z6D/dfXiUYxERkeqpz1LSqcDn7r6o\nHr+niIjsovoMhlHAU1XsO87MZpjZK2Z2eD2OSUREKqmXYDCzpsCZwF/T7J4KdHb3PsA9wAtVvMcY\nMysys6IVK1ZEN1gRkSxXXzOGocBUd/+q8g53X+vu6+OPJwFNzGy/NMc95O4F7l6w//77Rz9iEZEs\nVV/B8B2qKCOZWVszs/jjfvExldbTuEREpJJIVyUBmNmewCDgiqRtVwK4+4PASOAqM4sBm4BR7u5R\nj0tERNKLPBjcfSPQptK2B5Me3wvcG/U4RESkenTls4iIpFAwiIhICgWDiIikUDCIiEgKBYOIiKRQ\nMIiISAoFg4iIpFAwiIhICgWDiIikUDCIiEgKBYOIiKRQMIiISAoFg4iIpFAwiIhICgWDiIikUDCI\niEgKBYOIiKRQMIiISAoFg4iIpIg8GMxsoZl9bGbTzawozX4zs7vNbJ6ZfWRmfaMek4iIVC2vnr5P\nf3dfWcW+oUCP+NexwAPxP0VEJAMaQilpBPCYB5OBlmZ2UKYHJSLSIJSVwV//CieeCNOm1cu3rI9g\ncOB1Mys2szFp9rcHFic9L4lvS2FmY8ysyMyKVqxYEdFQRUQaiBUr4He/g65d4bzzYMmSsK0e1Ecw\nHO/ufQklo6vN7KRK+y3Na3y7De4PuXuBuxfsv//+UYxTRKThuPFGuOkmOOwweOkl+OwzGDy4Xr51\n5MHg7kvify4Hngf6VTqkBOiY9LwDsCTqcYmINBhlZfDMM6FcNGVK2HbjjTBrFrz+OgwfDrm59Tac\nSIPBzFqY2d6Jx8BgYGalwyYCF8ZXJxUCa9x9aZTjEhFpEJLLReefH8pFpaVhX9euYbaQAVGvSjoQ\neN7MEt/rSXd/1cyuBHD3B4FJwDBgHrARuCTiMYmIZF4sBkceCcuWwaBB8OCDMHRolTOD4kWrmTy/\nlMJubcjv3CrSoUUaDO4+H+iTZvuDSY8duDrKcYiIZFxZGbzwAkycCOPHQ14e3Hcf9Oq105lB8aLV\nXPDIZLbGymmal8OEywsjDYeGsFxVRKTxqry66P334csvw76zz65WuWjy/FK2xsopdyiLlTN5fmmk\nQ1YwiIhE5cMPoWPHsLro0EPDbOGzz8K2XVDYrQ3N8qBnTglN8nIo7NYmogEH9XXls4hI45coF23d\nChdcAEcfDddeC5dcUvMTyRtKyS+ZwLSWY8nbsJSZoz7gqN35HIOISFZYsQIefhjuvz+UiU48MQRD\nkyZw++27/n7usPgDKBoHs16AbVvYo9NxMOgmjurWru7HX4mCQUSkNu6+G264AbZsCauLHngAhg2r\n2XttXgsfPR0CYfkn0HRv6HshFFwKB9bf0lUFg4jIrigrg+efh2OPhc6doXdvuPRSuOaampeLlkwP\nYfDxs1C2AQ7qA2fcDb3PgWZ71e34q0HBICJSHZXLRbfcAjffDAMGhK9dtXUjzHouBMKXxZDXHI44\nJ8wO2vUFS9ctqH4oGEREdsQdrroK/vzninJR4mK0mlgxB4oehRlPwuY1sF9PGHIb9Dkfmkd7Urm6\nFAwiIpWVlcE//gEDB4bf3M1qVy6KbYXZL4VAWPhPyGkCh50JBZdB529ldHaQjoJBRCShcrloxozQ\ntuKBB2r2fqsXQvF4mPY4bFgBLTvBqb+Eo0fDXg23S7SCQURk2bLQzfTJJ1NXFx1++K6/V/k2mPs6\nTBkL894Ms4FDhoTZwcEDIKfhX1esYBCR7FRWFmYFXbrAnnvCK6/Urly0bhlMfSzMENaWwF5t4eQb\nwnLTfTvU+fCjpGAQkeySKBc98AC0bg3Tp8M++8AXX4QL0nZFeTks+EdYWTRnEpTHoFt/GPJ76DkU\ncnfx/RoIBYOIZIdZs+DOOyvKRQMHwnXXVezflVDYuAqmTwgnk1d9Ds1bQ+FVkH8JtDm47sdezxQM\nItJ4lZWF+x40bw7FxfD00zUvF7nD4g+haOw3bSroWAgn/xQOGwFN9ojmZ8gABYOIND7J5aLrr4cf\n/zjcIe3MM6Fly117r81r4eNnYMo4WD4r3qZidJgdtO0dzfgzTMEgIo3H9Omhd1Fyuejoo8O+Zs3C\nV3Ut/SjMDj76a2hT0fYIGP4nOOLcjLSpqE8KBhHZvblXXCB2ww3w73+HNtfXXrvr5aKyTTAz0aai\nCPL2gN4joeASaJ/f4C5Ei0pkwWBmHYHHgLZAOfCQu99V6ZhTgBeBBfFNz7n7r6Mak4g0IitXhnLR\nww/De+9Bhw7hwrQ2baDVLraWWPEZFD8aTihvXgP7HQJDboU+oxpMm4r6FOWMIQb8t7tPNbO9gWIz\ne8PdP6l03D/dfXiE4xCRxiRduWjNmhAM3btX/31iW2H2y2F2kGhTcegZoYldlxOyZnaQTmTB4O5L\ngaXxx+vM7FOgPVA5GEREqmf5cigoCOcKarq6aPUimDoepj4OG5bDvp3g1JvjbSoOiGbcu5l6Ocdg\nZl2Ao4EP0uw+zsxmAEuAH7v7rCreYwwwBqBTp07RDFREGpZEueizz+DRR+GAA8K9EE48cddWF5Vv\ng7lvhJPJc98Is4Eep8ExiTYVudH9DLuhyIPBzPYC/gb80N3XVto9Fejs7uvNbBjwAtAj3fu4+0PA\nQwAFBQUe4ZBFJNOmTYN77kktF23ZEmYKZ5xR/fdZtyzMDIr/HG9TcSCc9GPoexG07BjZ8Hd3kQaD\nmTUhhMIEd3+u8v7koHD3SWZ2v5nt5+4roxyXiDRgTzwBo0eH/kWXXBLKRbvSzM69ok3F7L/H21Sc\nAkN+Bz2H7bZtKupTlKuSDBgLfOru/1vFMW2Br9zdzawfkAOURjUmEWmAEuWiQw+Fs84K90u+884Q\nCruyumjjKpj+ZFhdVDovrCY69spwIdp+u3BSWiKdMRwPjAY+NrPp8W03Ap0A3P1BYCRwlZnFgE3A\nKHdXmUgkG1QuF113XQiG1q3hRz+q3nu4Q8mUMDuY+Vy8TcWxcNJP4LCz6qRNRfGi1UyeX0phtzbk\nd86OpatRrkr6F7DD9V7ufi9wb1RjEJEGasyYMEtIlIt29WK0Levgo2dCE7uvPoame8HR3wtLTeuw\nTUXxotVc8MhktsbKaZqXw4TLC7MiHHTls4hEb+VKeOQR+MEPQovrwYOhV6+dlou2+2196UdhdvDx\nX2Hr+qQ2FSOh2d51PuzJ80vZGiun3KEsVs7k+aUKBhGRWql8MVqPHnDOOTBy5E5fmvht3WKbWdzk\nA3oeOJm9VkyLt6k4J8wOIm5TUditDU3zciiLldMkL4fCbm0i+14NiYJBROrehg0wdCj88581LhfN\nnlnMT3w85zR9j5a2gdXrO8Npvw9tKvZsHeHgK+R3bsWEywt1jkFEpEZWroT33w+trVu0CLfMPOus\nXVtdFNsKc/4OReO4YMF7lOXm8nr5MTzDIK47/1Lyu9RPICTL79wqawIhQcEgIrUzfXpYXTRhQlgl\ntGxZCILHHqv+e3z9RbhX8tTHKtpUDPgFn+x/BguX5XJdFv223hAoGESkZmbMCEtM33sv9WK06s4O\nyrfBvDdhyliY+3rYdshpUHAZdD8VcnLpA/Q5NLKfQKqgYBCR6lu5MnQyPfjgsLpoyRK4447Q0K66\ngbDuK5j2WJghrFmc1KbiQmipPmgNgYJBRHYuuVw0cCC8/DJ07Rqa21VnVZB7aG09ZWxodV0eg64n\nw+DfQq/T1aaigVEwiEjVXn0Vfv/77ctFCTsLhY2rYMZT4dqD0nmwR0u1qdgNKBhEJNXKlbDvvtCk\nCRQVweLFu1YucoeSohAGs56D2Gbo0A++/X9w2Aho0jz6n0FqxXbH1kQFBQVeVFSU6WGINC7J5aLH\nHoPzzoNNm6BpU8itxv0KtqwLVyRPGVfRpuLI8+JtKo6IfvyyU2ZW7O4FOztOMwaRbFZeDs89F65O\nTlyMdvHFcNRRYX/zavx2v2xmuAHOR8+ENhUHHgHD/whHnBtJmwqJnoJBJBtt3RpmAmbwi1+EdhW7\nUi4q2wSzXgjlopIPQ5uKw88Os4MOBVl9v+TGQMEgkk0S5aJXXoG5c8MVyq++Ch06VK9ctHJeuN/B\n9AmwaTW06Q6n/Q76fKfe2lRI9BQMIo1dLAYvvBACIbG66MILYePGEAydO2/3kpSuph32CndCKxoX\n7oyWkwe9hof7JXc5UbODRkjBINLYTZ8O554brjuoRrko0dV0v9hyrMk7HNniXzTZtOKbNhUcPRr2\nPrAefwCpbwoGkcYmUS5q3hzuvRcKCuDtt+Gkk3ZeLirfxtIpL3Iv4+nfdBoGLGp+Al2/fR90Hwg5\n1Sg3yW5PwSDSGCTKRcmri8aMqdjfv/+OX79+OUx7HIr/zPCvv2BFzr48uG0Ef7NTuX3EGXRVA7us\nEnkwmNkQ4C4gF3jE3W+ttL8Z8BiQD5QC57v7wqjHJdKo3HxzuEK5S5fqry5yh4X/CktNP30Zysug\n60kw6Dd8see3YOFabldX06wUaTCYWS5wHzAIKAGmmNlEd/8k6bDLgNXu3t3MRgG3AedHOS6Rhqra\nN55PlIsuvhhOPBEuvxyOPRaGD995uWjTapieaFMxN96m4grIvxj26wGE39Lyux5QVz+W7GainjH0\nA+a5+3wAM/sLMAJIDoYRwK/ij58F7jUz893xkmyRWtjpjedjMXjxxVAuSqwuKiwMwdCtW/iqijt8\nWRzCYObfKtpUnPUgHH6W2lRIiqiDoT2wOOl5CXBsVce4e8zM1gBtgJXJB5nZGGAMQKdOas0rjc8O\nbzzvDt/6FkyZsmvloi3rQ5uKonGw7KPQpuKo76pNhexQ1MGQboFz5ZlAdY7B3R8CHoLQK6n2QxNp\nWCrfeL7/5qXw4wfhtttCeejaa8M9EKpTLvpqVgiDGU/D1nVwYG84/X9D7yK1qZCdiDoYSoCOSc87\nAEuqOKbEzPKAfYFVEY9LpMHJ79yKCRcXsPyJpzlh0lPs/dv3w5LT0aOhT5/w546UbYZPXgwnkxd/\nALnNoPfZ4Y5oalMhuyDqYJgC9DCzrsCXwCjgu5WOmQhcBPwHGAm8rfMLkpXmzye//ymhzfWulItK\nPw+zA7WpkDoSaTDEzxlcA7xGWK46zt1nmdmvgSJ3nwiMBR43s3mEmcKoKMck0qDMmAELFsBZZ4XW\nFCefDOecA2ecseNy0bYymDMpBML8dyvaVBRcGpacanYgtaD7MYjUt8qrizp3hvnzISdn569dUxLu\nlTz1MVi/DPbtCPkXwdEXqk2F7JTuxyDSEE2cGG6NuXhxCITbbw/loh2FQvk2+PztcL/kua+FFUo9\nBkPBXdBjkNpUSJ1TMIhEbcYMaNkyBEHr1tCjR7g4bWeri5LaVPD1F9DiADjhv8KFaC21ZFuio2AQ\niULlctE114QwOOEEeOutql/nDov+HWYHn74U2lR0OREG/Rp6ng55TevvZ5CspWAQqWt33QV33lmx\nuihRLtqRTathxl/CyeSVn4U2Ff3GhNnB/ofUx6hFvqFgEKkLs2dDz55hNdAnn8Ahh+y8XOQOX05N\nalOxCTocAyPuD9cfqE2FZIiCQaSmKpeL/vOf0Lvovvsgbwf/tLash5nPhnLRso+gSQvoMyosNT3o\nyPobv0gVFAwiu2r9+nADnPvvT70YrVevsL+qUKiqTcUR58Ie+9Tb8EV2RsEgUl1r1sC++4alpXfc\nEdpU7Kxc9E2binGweHJoU3H4t8P9kjscowvRpEFSMIjsSHK5aOnScC5hzz1hzhxo06bq15V+DsWP\nwrQJsGkVtD4YBv+/0NlUbSqkgVMwiKRTWgqPPBLOFyTKRVdfDWVl0KxZ+lDYVgZzXglN7L5pU3F6\nOHfQ5aTqXdks0gAoGESSlZeH/8DffRd+9jMYMGDn5aI1JaFFRfH40KZinw7Q/3+g72jYu229Dl+k\nLigYRGKx0Kri7rtDENx8M4wYATNnwuGHp39NeTl8/lY4d/DZq/E2FYOg4E+hXYXaVMhuTMEg2aty\nuahzZ2jXLuzLy0sfCutXxNtUPBpvU7E/HP/DcCFaq871OnyRqCgYJHtdcQX87W9hlnD33VW3uk60\nqSgaB59MrGhTMfBX0OsMtamQRkdttyU7JMpF99wDDz8M3buHUhFA797pX7Pp66Q2FXNgj32hT/x+\nyWpTIbshtd0WgfTloi++CMGQLhDStalonx/aVBz+bWi6Z/3/DCL1TMEgjdemTSEAvv4a+vffYblo\n2rwSvv7wSfqVvkiL0pnxNhXnQ/4l0O6oDAxeJHMUDNJ4JMpF//hH6HDavDn88Y+Qnw9HHJH+NV99\nwvJ3HqD7p39lb9vEZ96RPY77DZ1OuSiUjkSyUCTBYGa3A2cAW4HPgUvc/es0xy0E1gHbgFh1al8i\n20lXLrr55nAR2sUXb3982Wb4dGJoYrd4Mq2tKS+V9+OJ2KlM5xB+1KwXVysUJItFNWN4A/i5u8fM\n7Dbg58BPqzi2v7uvjGgc0ti98w4MGwabN+98dVHp5+FuaNOeiLep6AaDf8vMNsP4+ROfUUY5TfJy\nKOy2g1YXIlkgkmBw99eTnk4GRkbxfSQLJcpFTZuGq5GPOQYuuwyuvDL9yeRtMfjslTA7mP8OWC70\nGgYFl0HXkyEnh6OACZe3ZvL8Ugq7tSG/c6t6/7FEGpLIl6ua2UvA0+7+RJp9C4DVgAP/5+4P7eB9\nxgBjADp16pS/aNGiiEYsDVKiXHT//WFV0dChMGlS1cev+RKmjg+tKtYthX3ah4vQjh4N+xxUb8MW\naUgiX65qZm8C6RrB3OTuL8aPuQmIAROqeJvj3X2JmR0AvGFms939vXQHxkPjIQjXMdR03LIbuv32\ncM4guVw0fPj2x5WXw+dvx9tUvBKWnnYfGO550GMw5GqthUh11PhfirsP3NF+M7sIGA6c6lVMS9x9\nSfzP5Wb2PNAPSBsMkkUS5aKTToL99oOuXeHCC+Haa9OXi9avgOlPQNGj8PUi2HM/OP566HsRtO5a\n/+MX2c1FtSppCOFk88nuvrGKY1oAOe6+Lv54MPDrKMYju4nKq4v+9Ce4/noYOTJ8JXOHRe/H21S8\nGNpUdD4BTr0ZDj0D8ppl5mcQaQSimlvfCzQjlIcAJrv7lWbWDnjE3YcBBwLPx/fnAU+6+6sRjUca\nsm3b4Kqr4PHHQ7ko+WK0yjZ9DR89HQJhxWxoti8cczkUXAL796z/sYs0QlGtSupexfYlwLD44/lA\nnyi+v+wGYjGYMgWOOy4sLS0tDeWia65JfzFacpuKso3xNhX3weFnq02FSB3T2TipX8mri0pKYMEC\n6NQJnn12+/sfb90QgmDKWFg6HZrsCUecG2YH7Y7OzPhFsoCCQepHSQnccgs88URFueiuu6B9+7A/\nORSWfxpmBzP+AlvWwv6HwrA74Mjz1KZCpB4oGCQ6sRisWAEHHRRul/nMM1WXi2Jbwr0OisbBF+9D\nblM47KzQ4rpT4fazCRGJjIIhixUvWh3N1b7J5aLu3eGtt8Kd0ZYtC43tkq1aEO6GNu0J2FgKrbrC\noN/AURdAC7WmEMkEBUOWKl60mgsemczWWDlN83KYcHlh7cNh1qywxDS5XHTttRX7E6GwLRbuk1w0\nLtw3+Zs2FZdC11PC7EJEMkbBkKUmzy9la6yccoeyWDmT55fWLBhisXBNQZMm8PrrMGECjB4dAqFy\nuWjtktCiong8rFsCe7eDU26EvqNhn3Z184OJSK0pGLJUYbc2NM3LoSxWw46iq1ZVXIx2yy2hvfX3\nvw8XXQStW1ccV14emtcVjYM5r4CXQ/dT4fQ7oMdpalMh0gDpX2WWyu/cigmXF+76OYaPPgr3TZ4w\nIdwhrX//cP8DgL32qjhuw0qYPiG0qVi9ILSp+Na1oZGd2lSINGgKhiyW37lV9QLBvWJV0MUXw+zZ\n8L3vbV8ucocvJkPR2NCmYtvW0KZiwP+oTYXIbkTBIFUrLYWxY2H8ePj3v6Fly/C4ffvUctHmNTAj\n0abi09CmouDScL/kA3plbvwiUiMKBtleolyUWF10yinheoSWLVNnCEumhTD4+NnQpqJdXzjzXuh9\nNjRtkbHhi0jtKBgk1fz50KdPWFqabnXR1o2hTUXROFgyNd6mYmSYIahNhUijoGDIdonVRcuXwx13\nQLdu4cTykCGp5aLls8OFaNOfgi1r1KZCpBFTMGSrjz+uKBdt2gSDB4f217m58N3vhmNiW+DTl8Ls\nYNG/1aZCJEsoGLLRgw+G+x/ssUf6ctGqBVD853ibipXxNhW/jrep2C9jwxaR+qFgyAaJclG/fuFE\n8rBh8Ic/wGWXVZSLtsVg7mthdjDvLbAc6Dk0zA669VebCpEsomBozCpfjPazn4Vg6NQJfvKTcMza\nJTD1cZg6HtZ+GW9T8TPoe6HaVIhkKQVDBkTW1TTZ6NHh/EHz5ttfjFZeDgveDbOD2ZPAt8HBp8Kw\n2+u9TUW9fBYisksi+x/AzH4FfB9YEd90o7tPSnPcEOAuIJdwP+hboxpTQxBJV1MI5aLHHoMf/ACa\nNoWTT4Yjj0wtF20oDW0qih+FVfNhzzYZbVMR2WchIrUS9a+Gf3T3O6raaWa5wH3AIKAEmGJmE939\nk4jHlTF11tU0ofLqokMPhdNOg8svD/vdYdF/wuzgkxfibSqOh/43ZbxNRZ1/FiJSJzJdSuoHzHP3\n+QBm9hdgBNBog6HWXU0TVq2CkSPhnXfSl4s2r4GPngmBsPwTaLZPaFFRcAkccGjd/UC1UGefhYjU\nqaiD4RozuxAoAv7b3VdX2t8eWJz0vAQ4Nt0bmdkYYAxAp06dIhhq/ahxV1MIYTB9OgwYAK1aheWm\nt90WykVt4v+pLpme1KZiQ7ga+cx7oPc5Da5NRa0+CxGJjLl7zV9s9ibQNs2um4DJwErAgd8AB7n7\npZVefy5wmrtfHn8+Gujn7teyAwUFBV5UVFTjce92kstFTZpsf4vMrRth1nMwZWxoU5HXvKJNRfu+\nmRu3iDQoZlbs7gU7O65WMwZ3H1jNwTwMvJxmVwnQMel5B2BJbcbUqBQVwQ03hHJR4mK0a66pCIUV\nc8Ls4Js2Fb1g6B/gyPOhecvMjl1EdltRrko6yN2Xxp9+G5iZ5rApQA8z6wp8CYwCvhvVmHYLq1aF\nk8jt24eWE59/nlouim0JZaKiR2HRvyCnCRw2Ao65DDodpzYVIlJrUZ5j+IOZHUUoJS0ErgAws3aE\nZanD3D1mZtcArxGWq45z91kRjqnhSi4XnX8+PPoo5OeHbqe5ubB6Ibx5T7gYbeNKaNUFBt4S2lTs\ntX+mRy8ijUhkweDuo6vYvgQYlvR8ErDd9Q1ZY9Kk0NU0US5KrC6CeJuK1+NtKt4Ms4Gew8LKom4D\n1KZCRCKR6eWq2Wn16nDTGzN4443ty0Vrl8K7tyW1qTgITv5paFOxb/tMj15EGrlarUrKlN12VVJy\nuejll8Oy03XrwsnknJw0bSoGhJVFhwyt1zYVItI41cuqJKmGbdtg4kS4+254992KclHH+GKsnK3w\nwaMVbSqat4bjrg5tKtocnMmRi0iWUjBEJXHTm23bKvoXJcpFrVvD4g/gudth1guwbUtYUXTKz+HQ\nM6HJHpkevYhkMQVDXUuUi957D2bODIHw7rtw8MEQ2wgfPQ1PPwrLZ0HTvcN5g4JL4cDDMj1yERFA\nwVA3KpeLEr2L1q8PJ5n32QyTflTRpqLtkXDGXdB7JDTbK9OjFxFJoWCoC2+9BWefHW6AkygX7d08\ntKkoGgdfFsfbVJwTZgft+upCNBFpsBQMNZEoF7VvD7/8JQwcCC+9BEOGwOrP4cPbYcaTocPpfj1h\nyG3Q53xoriZxItLwKRiqa9u28J//3XdXXIyWuBCtPAZdtsATZ8HCf8bbVJwZZgedj9fsQER2KwqG\n6vrhD+Hee1PLRTnr4M1bYNrjsGEFtOwEp/4Sjv4e7HVApkcsIlIjCoaqJMpF110HvXvD978P/fvD\n8NNhwdvwyhUVbSoOGQIFl4UL0tSmQkR2cwqGZOnKRSeeGIKh6wGw+lW4ty+sLYG92sLJN8TbVHTI\n9MhFROqMgiGhvBz69IFZsyrKRZdcAmtnwtOjYc6kcC6hW38Y8nvoORRym2R61CIidS67g2HmTHju\nOfjFL0IJ6IorwkqjgSfAzKfuHiPPAAAGrklEQVThqdNg1eehTUXhVeGeyWpTISKNXPYFQ7py0QUX\nQLduMKJfuO7gritDm4qOhaGr6WEj1KZCRLJGdgXDrFkwfDgsXBia2N16K3zvfFjyJrx+IXw1M96m\nYnSYHbTtnekRi4jUu+wKhoMPhiOPhDvvhGO6wPTHYPzxsHU9tD0Chv8JjjhXbSpEJKtlVzDkOvzq\nPCi6D8YWQd4e0PucsNS0vdpUiIhARMFgZk8DPeNPWwJfu/tRaY5bCKwDtgGx6txAosbKy+H+wnDv\n5P0OgSG3Qp9RalMhIlJJJMHg7ucnHpvZncCaHRze391XRjGOFDk54X4H+7SHLidodiAiUoVIS0lm\nZsB5wIAov0+19RmV6RGIiDR4UfdvOBH4yt3nVrHfgdfNrNjMxkQ8FhERqYYazxjM7E2gbZpdN7n7\ni/HH3wGe2sHbHO/uS8zsAOANM5vt7u9V8f3GAGMAOnXqVNNhi4jITpi7R/PGZnnAl0C+u5dU4/hf\nAevd/Y6dHVtQUOBFRUW1H6SISBYxs+LqLPKJspQ0EJhdVSiYWQsz2zvxGBgMzIxwPCIiUg1RBsMo\nKpWRzKydmU2KPz0Q+JeZzQA+BP7u7q9GOB4REamGyFYlufvFabYtAYbFH88H+kT1/UVEpGZ0VxkR\nEUmhYBARkRQKBhERSaFgEBGRFAoGERFJkVXBULxoNfe9M4/iRaszPRQRkQYra+7HULxoNRc8Mpmt\nsXKa5uUw4fJC8jur5baISGVZM2OYPL+UrbFyyh3KYuVMnl+a6SGJiDRIWRMMhd3a0DQvh1yDJnk5\nFHZrk+khiYg0SFlTSsrv3IoJlxcyeX4phd3aqIwkIlKFrAkGCOGgQBAR2bGsKSWJiEj1KBhERCSF\ngkFERFIoGEREJIWCQUREUigYREQkhYJBRERSKBhERCRFrYLBzM41s1lmVm5mBZX2/dzM5pnZHDM7\nrYrXdzWzD8xsrpk9bWZNazMeERGpvdrOGGYCZwPvJW80s8OAUcDhwBDgfjPLTfP624A/unsPYDVw\nWS3HIyIitVSrYHD3T919TppdI4C/uPsWd18AzAP6JR9gZgYMAJ6NbxoPnFWb8YiISO1F1SupPTA5\n6XlJfFuyNsDX7h7bwTHfMLMxwJj40/Vmli6QqmM/YGUNX9sY6fOooM8ilT6PCo3ls+hcnYN2Ggxm\n9ibQNs2um9z9xapelmab1+CYih3uDwEPVbW/usysyN0Ldn5kdtDnUUGfRSp9HhWy7bPYaTC4+8Aa\nvG8J0DHpeQdgSaVjVgItzSwvPmtId4yIiNSzqJarTgRGmVkzM+sK9AA+TD7A3R14BxgZ33QRUNUM\nRERE6kltl6t+28xKgOOAv5vZawDuPgt4BvgEeBW42t23xV8zyczaxd/ip8CPzGwe4ZzD2NqMp5pq\nXY5qZPR5VNBnkUqfR4Ws+iws/OIuIiIS6MpnERFJoWAQEZEUWRMMZjYk3p5jnpn9LNPjySQz62hm\n75jZp/GWJtdnekwNgZnlmtk0M3s502PJJDNraWbPmtns+N+R4zI9pkwys/+K/zuZaWZPmdkemR5T\n1LIiGOLtOO4DhgKHAd+Jt+3IVjHgv939UKAQuDrLP4+E64FPMz2IBuAu4FV37wX0IYs/EzNrD1wH\nFLh7byCX0O6nUcuKYCC045jn7vPdfSvwF0Lbjqzk7kvdfWr88TrCP/wqrzrPBmbWATgdeCTTY8kk\nM9sHOIn4CkF33+ruX2d2VBmXBzQ3szxgT7LgeqtsCYb2wOKk5ztsv5FNzKwLcDTwQWZHknF/Am4A\nyjM9kAzrBqwAHo2X1R4xsxaZHlSmuPuXwB3AF8BSYI27v57ZUUUvW4Jhl9pvZAsz2wv4G/BDd1+b\n6fFkipkNB5a7e3Gmx9IA5AF9gQfc/WhgA5C15+TMrBWhutAVaAe0MLPvZXZU0cuWYKhOi46sYmZN\nCKEwwd2fy/R4Mux44EwzW0goMw4wsycyO6SMKQFK3D0xg3yWEBTZaiCwwN1XuHsZ8BzwrQyPKXLZ\nEgxTgB7xGwM1JZw8mpjhMWVMvOX5WOBTd//fTI8n09z95+7ewd27EP5uvO3ujf63wnTcfRmw2Mx6\nxjedSuhgkK2+AArNbM/4v5tTyYKT8VG13W5Q3D1mZtcArxFWFYyLt+3IVscDo4GPzWx6fNuN7j4p\ng2OShuNaYEL8l6j5wCUZHk/GuPsHZvYsMJWwmm8aWdAeQy0xREQkRbaUkkREpJoUDCIikkLBICIi\nKRQMIiKSQsEgIiIpFAwiIpJCwSAiIin+PxM/aZvjOT0fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c6c9d403c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y, '.')\n",
    "plt.plot(np.matmul(X,W))\n",
    "plt.plot(6*x - 1.0, 'r--')\n",
    "plt.ylim(-10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além de saber se função está sendo minimizada, é importante ver como ela está sendo minimizada. Assim, o código normalmente coleta mais informações, mas com o cuidado de não interferir constantemente com a otimização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gdtf(X, y, n_epochs = 100, lrating = 0.1):\n",
    "    m, n = X.shape\n",
    "    \n",
    "    X = tf.constant(X, dtype = tf.float32, name = \"X\")\n",
    "    y = tf.constant(y.reshape(-1, 1), dtype = tf.float32, name = \"y\")\n",
    "    W = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), name = \"W\")\n",
    "    \n",
    "    Yhat = tf.matmul(X, W, name = \"predictions\")\n",
    "    error = Yhat - y\n",
    "    loss = tf.reduce_mean(tf.square(error), name = \"loss\")\n",
    "    gloss = (2./m) * tf.matmul(tf.transpose(X), error)\n",
    "    training = tf.assign(W, W - lrating * gloss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    lossvalues = []\n",
    "    with tf.Session() as s:\n",
    "        s.run(init)\n",
    "        for e in range(n_epochs):\n",
    "            s.run(training)\n",
    "            lossvalues += [loss.eval()]  # guardando os valores de perda\n",
    "            if e%10==0:                  # evitando I/O a cada rodada\n",
    "                print(lossvalues[-1])\n",
    "        finalW = W.eval()\n",
    "    return finalW, lossvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W, lossvalues = gdtf(X, y, n_epochs=100)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(lossvalues[:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que deveriamos evitar avaliar o grafo múltiplas vezes para obter valores de nós. O ideal é obter todos os valores de interesse em uma única avaliação, como feito abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gdtf(X, y, n_epochs = 100, lrating = 0.1):\n",
    "    m, n = X.shape\n",
    "    \n",
    "    X = tf.constant(X, dtype = tf.float32, name = \"X\")\n",
    "    y = tf.constant(y.reshape(-1, 1), dtype = tf.float32, name = \"y\")\n",
    "    W = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), name = \"W\")\n",
    "    \n",
    "    Yhat = tf.matmul(X, W, name = \"predictions\")\n",
    "    error = Yhat - y\n",
    "    loss = tf.reduce_mean(tf.square(error), name = \"loss\")\n",
    "    gloss = (2./m) * tf.matmul(tf.transpose(X), error)\n",
    "    training = tf.assign(W, W - lrating * gloss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    lossvalues = []\n",
    "    with tf.Session() as s:\n",
    "        s.run(init)\n",
    "        for e in range(n_epochs):\n",
    "            W_e, loss_e = s.run([training, loss]) # Roda o grafo uma unica vez para treino e perda\n",
    "            lossvalues += [loss_e]\n",
    "            if e%10==0:\n",
    "                print(lossvalues[-1])\n",
    "    return W_e, lossvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W, lossvalues = gdtf(X, y, n_epochs=100)\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferenciação automática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que a função a ser diferenciada depende do estimador, da ativação, da função de perda e do regularizador. Logo, ela pode ser bastante complexa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estas situações, o TF ajuda com um mecanismo de auto diferenciação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# autodiferenciador\n",
    "def gdtf2(X, y, n_epochs = 100, lrating = 0.1):\n",
    "    m, n = X.shape\n",
    "        \n",
    "    X = tf.constant(X, dtype = tf.float32, name = \"X\")\n",
    "    y = tf.constant(y.reshape(-1, 1), dtype = tf.float32, name = \"y\")\n",
    "    W = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), name = \"W\")\n",
    "    \n",
    "    Yhat = tf.matmul(X, W, name = \"predictions\")\n",
    "    error = Yhat - y\n",
    "    loss = tf.reduce_mean(tf.square(error), name = \"loss\")\n",
    "    # gradients(funcao de perda, variaveis) --> [gradiente parcial em cada variavel]\n",
    "    gloss = tf.gradients(loss, [W])[0]\n",
    "    training = tf.assign(W, W - lrating * gloss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    lossvalues = []\n",
    "    with tf.Session() as s:\n",
    "        s.run(init)\n",
    "        for e in range(n_epochs):\n",
    "            W_e, loss_e = s.run([training, loss])\n",
    "            lossvalues += [loss_e]\n",
    "            if e%10==0:\n",
    "                print(loss_e)\n",
    "    return W_e, lossvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W, _ = gdtf2(X, y, n_epochs=100)\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferentes otimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como lidar com mínimos locais e _saddle points_?? (pontos em que eixos representam concavidades opostas, muitas vezes não fáceis de detectar devido a platôs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/NY-UOaLbhrE\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma possibilidade para lidar com estes problemas é usar diferentes otimizadores, como os descritos a seguir:\n",
    "\n",
    "* _SGD_: gradiente descendente estocástico. Usa gradiente da função para determinar direção e distância do ponto de mínimo. Ele corresponde ao GD clássico (_batch GD_) considerando estimativas baseadas em uma única instância $x_i$; se mais instâncias forem usadas, digamos $b$ instâncias, tal que $b << m$, então o algoritmo é chamado de GD (ou SGD, dependendo dos autores) com mini lotes, cada lote com tamanho $b$ (mini-batch [stochastic] gradient descent);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Momento_: atualização dos pesos depende de útima atualização, de forma que o impulso anterior interfere no comportamento atual (mais adiante). Supondo uma bolinha descendo um morro, ela vai ficando cada vez mais rápida à medida que desce. Algumas variantes deste algorimo podem incorporar ruído Gaussiano;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Gradiente Acelerado de Nesterov_ (NAG): o momento é corrigido pelo efeito que ele vai ter. Intuitivamente, é como se o comportamento fosse baseado no impulso (passado) corrigido pelo comportamento que se vai adquirir em seguida (futuro). Supondo a bolinha descendo o morro, ela vai desacelerando à medida que se aproxima de um novo morro (isso diminui o efeito de vai-e-vem perto do mínimo);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Adagrad_: Os métodos anteriores supõem que uma mesma taxa de atualização $\\eta$ deve ser aplicada para todos os parâmetros $w_0, w_1, ..., w_n$. Adagrad é um método adaptativo que aplica um valor distinto de $\\eta$ ($\\eta_0, \\eta_1, ..., \\eta_n$) para cada parâmetro de acordo com os valores anteriores observados para esse parâmetro. A ideia é atualizar _mais_ parâmetros associados a atributos observados menos frequentemente; e _menos_, parâmetros associados a atributos mais frequentes. Estes métodos são particularmente rápidos para problemas em que há atributos esparsos como em linguagem natural. Uma vantagem desse método é não ser necessário adotar uma política manual de atualização de um $\\eta$ global. Uma desvantagem é que a taxa de aprendizado tende à zero com o tempo;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Adadelta_: extensão de Adagrad que tenta resolver o problema de sumiço de $\\eta$ baseando a adaptação em uma janela de valores do passado de tamanho fixo em lugar de todos os valores;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _RMSProp_: método proposto por Hinton, quase ao mesmo tempo que o Adadelta, para corrigir o problema do Adagrad. Embora haja pequenas diferenças em relação ao Adadelta, eles se baseiam em ideias muito similares;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Adam_, _AdaMax_ e _Nadam_: modificações de Adadelta (Adam e AdaMax) e RMSProb (Nadam) para incorporar momento aos métodos adaptativos;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em geral, estes algoritmos buscam lidar melhor com diferentes topologias que o SGD. Por exemplo, veja o caso de superfícies com simetrias (as animações abaixo são de Alec Radford): algoritmos baseados em momento exploram até encontrar saída; os adaptativos rapidamente começam a descer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/LongValleyImgur.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso de superfícies com _saddle points_, o SGD se mostra claramente muito lento; os de momento repetem seu comportamento exploratório; os adaptativos novamente são muito rápidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/SaddlePointImgur.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, um exemplo de uso de um otimizador de momento no TF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# otimizadores\n",
    "def gdtf3(X, y, n_epochs = 100, lrating = 0.1):\n",
    "    m, n = X.shape\n",
    "    \n",
    "    X = tf.constant(X, dtype = tf.float32, name = \"X\")\n",
    "    y = tf.constant(y.reshape(-1, 1), dtype = tf.float32, name = \"y\")\n",
    "    W = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), name = \"W\")\n",
    "    \n",
    "    Yhat = tf.matmul(X, W, name = \"predictions\")\n",
    "    loss = tf.reduce_mean(tf.square(Yhat - y), name = \"loss\")\n",
    "    \n",
    "    #otimizador = tf.train.GradientDescentOptimizer(learning_rate = lrating)\n",
    "    otimizador = tf.train.MomentumOptimizer(learning_rate = lrating, momentum = 0.9)\n",
    "    training = otimizador.minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    lossvalues = []\n",
    "    with tf.Session() as s:\n",
    "        s.run(init)\n",
    "        for e in range(n_epochs):\n",
    "            W_e, loss_e = s.run([training, loss])\n",
    "            lossvalues += [loss_e]\n",
    "            if e%10==0:\n",
    "                print(loss_e)\n",
    "    return W_e, lossvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W, _ = gdtf3(X, y, n_epochs=100)\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O otimizador baseado em momento, usado no programa acima, \"lembra\" a última atualização e a repete em parte -- algo como descrito na Equação abaixo:\n",
    "\n",
    "$$\\textbf{w}' = \\textbf{w} + \\mu * v - \\eta \\nabla\\ell$$\n",
    "\n",
    "onde $\\mu$ é o quanto a última atualização $v$ deve ser lembrada. Um típico valor de de $\\mu$ pode ser 0.9. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício**: Compare os otimizadores, usando 40 épocas: \n",
    "* GradientDescentOptimizer(learning_rate = 0.1)\n",
    "* AdagradOptimizer(learning_rate = 1.0)\n",
    "* RMSPropOptimizer(learning_rate = 0.1)\n",
    "* AdamOptimizer(learning_rate = 1.0)\n",
    "\n",
    "Uma vez que tiver obtido as curvas de perda para cada método (ls_sgd, ls_adag, ls_rms e ls_adam) você pode plotá-las com o código abaixo:\n",
    "\n",
    "```python\n",
    "# gráficos\n",
    "plt.plot(ls_sgd, label = 'sgd')\n",
    "plt.plot(ls_adag, label = 'adag')\n",
    "plt.plot(ls_rms, label = 'rms')\n",
    "plt.plot(ls_adam, label = 'adam')\n",
    "plt.legend()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#losses\" class=\"btn btn-default\" data-toggle=\"collapse\">Solução #1</a>\n",
    "</div>\n",
    "<div id=\"losses\" class=\"collapse\">\n",
    "```\n",
    "# otimizadores\n",
    "def gdtf_opt(X, y, n_epochs = 100, lrating = 0.1, \n",
    "             otimizador = None):\n",
    "    m, n = X.shape\n",
    "    \n",
    "    X = tf.constant(X, dtype = tf.float32, name = \"X\")\n",
    "    y = tf.constant(y.reshape(-1, 1), dtype = tf.float32, name = \"y\")\n",
    "    W = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), name = \"W\")\n",
    "    \n",
    "    Yhat = tf.matmul(X, W, name = \"predictions\")\n",
    "    loss = tf.reduce_mean(tf.square(Yhat - y), name = \"loss\")\n",
    "    \n",
    "    training = otimizador.minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    lossvalues = []\n",
    "    with tf.Session() as s:\n",
    "        s.run(init)\n",
    "        for e in range(n_epochs):\n",
    "            W_e, loss_e = s.run([training, loss])\n",
    "            lossvalues += [loss_e]\n",
    "    return W_e, lossvalues\n",
    "\n",
    "# execução\n",
    "W, ls_sgd = gdtf_opt(X, y, n_epochs=40, \n",
    "             otimizador = tf.train.GradientDescentOptimizer(\n",
    "                 learning_rate = 0.1))\n",
    "W, ls_adag = gdtf_opt(X, y, n_epochs=40, \n",
    "             otimizador = tf.train.AdagradOptimizer(learning_rate = 1))\n",
    "W, ls_rms = gdtf_opt(X, y, n_epochs=40, \n",
    "             otimizador = tf.train.RMSPropOptimizer(learning_rate = 0.1))\n",
    "W, ls_adam = gdtf_opt(X, y, n_epochs=40, \n",
    "             otimizador = tf.train.AdamOptimizer(learning_rate = 1))\n",
    "\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento em lotes: os métodos estocásticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apenas relembrando placeholders..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "A = tf.placeholder(tf.float32, shape=(None,3))\n",
    "B = A + 5\n",
    "\n",
    "with tf.Session() as s:\n",
    "    b1 = s.run(B, feed_dict = {A: [[1,2,3]]})\n",
    "    \n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GD com batches --> gradiente descendente estocástico\n",
    "def gdtf4(Xi, yi, batch_size = 1, n_epochs = 100, lrating = 0.1):\n",
    "    def get_batch(batch_size):\n",
    "        ids = np.random.randint(Xi.shape[0], size = batch_size)\n",
    "        return Xi[ids, :], yi[ids,:]\n",
    "    \n",
    "    m, n = Xi.shape\n",
    "    yi = yi.reshape(-1,1)\n",
    "    \n",
    "    n_batches = int(np.ceil(float(m)/batch_size))\n",
    "    \n",
    "    X = tf.placeholder(dtype = tf.float32, shape=(None, n), name = \"X\")\n",
    "    y = tf.placeholder(dtype = tf.float32, shape=(None, 1), name = \"y\")\n",
    "    W = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), name = \"W\")\n",
    "    \n",
    "    Yhat = tf.matmul(X, W, name = \"predictions\")\n",
    "    loss = tf.reduce_mean(tf.square(Yhat - y), name = \"loss\")\n",
    "    \n",
    "    #otimizador = tf.train.GradientDescentOptimizer(learning_rate = lrating)\n",
    "    otimizador = tf.train.MomentumOptimizer(learning_rate = lrating, momentum = 0.9)\n",
    "    training = otimizador.minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    lossvalues = []\n",
    "    mlossvalues = []\n",
    "    with tf.Session() as s:\n",
    "        s.run(init)\n",
    "        for e in range(n_epochs):\n",
    "            mloss = 0.\n",
    "            for batch_index in range(n_batches):\n",
    "                # politica completamente estocastica!\n",
    "                Xb, yb = get_batch(batch_size)\n",
    "                _, W_e, loss_e = s.run([training, W, loss], feed_dict = {X: Xb, y: yb})\n",
    "                mloss += loss_e\n",
    "                lossvalues += [loss_e]\n",
    "            mloss = float(mloss) / n_batches\n",
    "            mlossvalues += n_batches * [mloss]\n",
    "            print(mloss)\n",
    "    return W_e, lossvalues, mlossvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W, lossvalues, mlossvalues = gdtf4(X, y, n_epochs=20, batch_size = 2, lrating = 0.01)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(y, '.')\n",
    "plt.plot(np.matmul(X,W))\n",
    "plt.plot(6*x - 1.0, 'r--')\n",
    "plt.ylim(-10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(lossvalues)\n",
    "plt.plot(mlossvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que muitas estratégias de batching podem ser usadas. Determinar o conjunto de exemplos de onde serão feitas as estimativas é parte importante de ML baseada em otimização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em longos processos de treino, é interessante salvar o estado geral dos parâmetros sendo aprendidos, de forma que seja possível retomar o processo mais tarde, partindo do último ponto de parada.\n",
    "\n",
    "É possível fazer isso em TF com checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "def gdtf5(Xi, yi, batch_size = 1, n_epochs = 1000, lrating = 0.01, \n",
    "          model_dir = '/tmp/model0tf.ckpt', save = True, restore = False):\n",
    "    def get_batch(batch_size):\n",
    "        ids = np.random.randint(Xi.shape[0], size = batch_size)\n",
    "        return Xi[ids, :], yi[ids,:]\n",
    "    \n",
    "    m, n = Xi.shape\n",
    "    yi = yi.reshape(-1,1)\n",
    "    \n",
    "    n_batches = int(np.ceil(float(m)/batch_size))\n",
    "    \n",
    "    X = tf.placeholder(dtype = tf.float32, shape=(None, n), name = \"X\")\n",
    "    y = tf.placeholder(dtype = tf.float32, shape=(None, 1), name = \"y\")\n",
    "    W = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), name = \"W\")\n",
    "    \n",
    "    Yhat = tf.matmul(X, W, name = \"predictions\")\n",
    "    loss = tf.reduce_mean(tf.square(Yhat - y), name = \"loss\")\n",
    "    \n",
    "    otimizador = tf.train.GradientDescentOptimizer(learning_rate = lrating)\n",
    "    #otimizador = tf.train.MomentumOptimizer(learning_rate = lrating, momentum = 0.9)\n",
    "    training = otimizador.minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    # init saving object\n",
    "    if save: saver = tf.train.Saver({\"W\": W})\n",
    "    \n",
    "    with tf.Session() as s:\n",
    "        if restore:\n",
    "            saver.restore(s, model_dir)\n",
    "        else:\n",
    "            s.run(init)\n",
    "        for e in range(n_epochs):\n",
    "            mloss = 0.\n",
    "            for batch_index in range(n_batches):\n",
    "                Xb, yb = get_batch(batch_size)\n",
    "                _, W_e, loss_e = s.run([training, W, loss], feed_dict = {X: Xb, y: yb})\n",
    "                mloss += loss_e\n",
    "            mloss = float(mloss) / n_batches\n",
    "            \n",
    "            if e%10 == 0:\n",
    "                print(mloss)\n",
    "                if save: \n",
    "                    print('checkpoint: saving model...')\n",
    "                    save_path = saver.save(s, model_dir)\n",
    "        if save: save_path = saver.save(s, model_dir)\n",
    "    return W_e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = gdtf5(X, y, n_epochs=1, batch_size = 2)\n",
    "W\n",
    "plt.plot(y, '.')\n",
    "plt.plot(np.matmul(X,W))\n",
    "plt.plot(6*x - 1.0, 'r--')\n",
    "plt.ylim(-10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = gdtf5(X, y, n_epochs=50, batch_size = 2)\n",
    "W\n",
    "plt.plot(y, '.')\n",
    "plt.plot(np.matmul(X,W))\n",
    "plt.plot(6*x - 1.0, 'r--')\n",
    "plt.ylim(-10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transferência de aprendizado v0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = gdtf5(X, y, n_epochs=1, batch_size = 2, restore = True)\n",
    "W\n",
    "plt.plot(y, '.')\n",
    "plt.plot(np.matmul(X,W))\n",
    "plt.plot(6*x - 1.0, 'r--')\n",
    "plt.ylim(-10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registros para acompanhamento -> logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# log \n",
    "def gdtf6(Xi, yi, batch_size = 1, n_epochs = 1000, lrating = 0.01, \n",
    "          model_dir = '/tmp/model0tf.ckpt', save = True, restore = False):\n",
    "    def get_batch(batch_size):\n",
    "        ids = np.random.randint(Xi.shape[0], size = batch_size)\n",
    "        return Xi[ids, :], yi[ids,:]\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    from datetime import datetime\n",
    "    \n",
    "    now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "    logdir = 'logs/run-' + now + '/'\n",
    "    \n",
    "    m, n = Xi.shape\n",
    "    yi = yi.reshape(-1,1)\n",
    "    \n",
    "    n_batches = int(np.ceil(float(m)/batch_size))\n",
    "    \n",
    "    X = tf.placeholder(dtype = tf.float32, shape=(None, n), name = \"X\")\n",
    "    y = tf.placeholder(dtype = tf.float32, shape=(None, 1), name = \"y\")\n",
    "    W = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), name = \"W\")\n",
    "    \n",
    "    Yhat = tf.matmul(X, W, name = \"predictions\")\n",
    "    loss = tf.reduce_mean(tf.square(Yhat - y), name = \"loss\")\n",
    "    \n",
    "    otimizador = tf.train.GradientDescentOptimizer(learning_rate = lrating)\n",
    "    #otimizador = tf.train.MomentumOptimizer(learning_rate = lrating, momentum = 0.9)\n",
    "    training = otimizador.minimize(loss)\n",
    "    \n",
    "    # log summary\n",
    "    loss_summary = tf.summary.scalar('loss-MSE', loss)\n",
    "    logfile = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    # init saving object\n",
    "    if save: saver = tf.train.Saver({\"W\": W})\n",
    "    \n",
    "    with tf.Session() as s:\n",
    "        if restore:\n",
    "            saver.restore(s, model_dir)\n",
    "        else:\n",
    "            s.run(init)\n",
    "        for e in range(n_epochs):\n",
    "            mloss = 0.\n",
    "            for batch_index in range(n_batches):\n",
    "                Xb, yb = get_batch(batch_size)\n",
    "                _, W_e, loss_e, summary_str = s.run([training, W, loss, loss_summary], \n",
    "                                                    feed_dict = {X: Xb, y: yb})\n",
    "                mloss += loss_e\n",
    "                # *** Na vida real fazer um log a cada batch eh muito caro ***\n",
    "                logfile.add_summary(summary_str, e*n_batches + batch_index)\n",
    "            mloss = float(mloss) / n_batches\n",
    "            \n",
    "            if e%10 == 0:\n",
    "                print(mloss)\n",
    "                if save: \n",
    "                    print('checkpoint: saving model...')\n",
    "                    save_path = saver.save(s, model_dir)\n",
    "        if save: save_path = saver.save(s, model_dir)\n",
    "    logfile.close()        \n",
    "    \n",
    "    return W_e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = gdtf6(X, y, n_epochs=10, batch_size = 2)\n",
    "W\n",
    "plt.plot(y, '.')\n",
    "plt.plot(np.matmul(X,W))\n",
    "plt.ylim(-10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W = gdtf6(X, y, n_epochs=100, batch_size = 10)\n",
    "W\n",
    "plt.plot(y, '.')\n",
    "plt.plot(np.matmul(X,W))\n",
    "plt.ylim(-10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para observar so carregar servidor tensorboard e ir para o endereço localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhorando logs com escopos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scopes\n",
    "def gdtf8(Xi, yi, batch_size = 1, n_epochs = 1000, lrating = 0.01, \n",
    "          model_dir = '/tmp/model0tf.ckpt', save = True, restore = False):\n",
    "    def get_batch(batch_size):\n",
    "        ids = np.random.randint(Xi.shape[0], size = batch_size)\n",
    "        return Xi[ids, :], yi[ids,:]\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    from datetime import datetime\n",
    "    \n",
    "    now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "    logdir = 'logs/run-' + now + '/'\n",
    "    \n",
    "    m, n = Xi.shape\n",
    "    yi = yi.reshape(-1,1)\n",
    "    \n",
    "    n_batches = int(np.ceil(float(m)/batch_size))\n",
    "    \n",
    "    X = tf.placeholder(dtype = tf.float32, shape=(None, n), name = \"X\")\n",
    "    y = tf.placeholder(dtype = tf.float32, shape=(None, 1), name = \"y\")\n",
    "    W = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), name = \"W\")\n",
    "    \n",
    "    Yhat = tf.matmul(X, W, name = \"predictions\")\n",
    "    \n",
    "    with tf.name_scope('loss'):\n",
    "        error = Yhat - y\n",
    "        mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "    \n",
    "    otimizador = tf.train.GradientDescentOptimizer(learning_rate = lrating)\n",
    "    training = otimizador.minimize(mse)\n",
    "    \n",
    "    # log summary\n",
    "    loss_summary = tf.summary.scalar('loss-MSE', mse)\n",
    "    logfile = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    # init saving object\n",
    "    if save: saver = tf.train.Saver({\"W\": W})\n",
    "    \n",
    "    with tf.Session() as s:\n",
    "        if restore:\n",
    "            saver.restore(s, model_dir)\n",
    "        else:\n",
    "            s.run(init)\n",
    "        for e in range(n_epochs):\n",
    "            mloss = 0.\n",
    "            for batch_index in range(n_batches):\n",
    "                Xb, yb = get_batch(batch_size)\n",
    "                _, W_e, loss_e, summary_str = s.run([training, W, mse, loss_summary], \n",
    "                                                    feed_dict = {X: Xb, y: yb})\n",
    "                mloss += loss_e\n",
    "                # *** Na vida real fazer um log a cada batch eh muito caro ***\n",
    "                logfile.add_summary(summary_str, e*n_batches + batch_index)\n",
    "            mloss = float(mloss) / n_batches\n",
    "            \n",
    "            if e%10 == 0:\n",
    "                print(mloss)\n",
    "                if save: \n",
    "                    print('checkpoint: saving model...')\n",
    "                    save_path = saver.save(s, model_dir)\n",
    "        if save: save_path = saver.save(s, model_dir)\n",
    "            \n",
    "    logfile.close()        \n",
    "    return W_e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = gdtf8(X, y, n_epochs=100, batch_size = 10)\n",
    "W\n",
    "plt.plot(y, '.')\n",
    "plt.plot(np.matmul(X,W))\n",
    "plt.ylim(-10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Regressor Logístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta vez, vamos usar um regressor logístico, ou seja, nosso estimador vai usar como função de ativação a função sigmoid. Nosso interesse nesses regressores é o fato de que eles podem ser usados para modelar neurônios:\n",
    "\n",
    "* Entradas $X$ do regressor corrspondem aos sinais recebidos de outros neurônios, via sinapses através dos dentritos;\n",
    "* Pesos $\\bf{w}$ correspondem à permeabilidade elétrica dos dentritos, ou seja, a importância da conexcão com cada neurônio particular na entrada;\n",
    "* A saída no fim dos axônios corresponde à estimativa $\\sigma(X \\bf{w})$, com $\\sigma$ indicando uma função sigmoid.\n",
    "\n",
    "Vamos observar a função sigmoid e sua derivada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "xis = tf.placeholder(tf.float32, name = 'xis')\n",
    "sigmoid = 1. / (1 + tf.exp(-xis))\n",
    "dsigf = tf.gradients(sigmoid, [xis])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xvals = np.linspace(-7, 7, 50)\n",
    "\n",
    "with tf.Session() as s:\n",
    "    sv, dsv = s.run([sigmoid, dsigf], feed_dict = {xis: xvals})\n",
    "\n",
    "plt.plot(xvals,sv)\n",
    "plt.plot(xvals,dsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função sigmoid converte qualquer número para o intervalo 0 a 1. Ela produz gradientes positivos na redondeza de $y$ = 0.5.\n",
    "\n",
    "Ao usar uma sigmoid, o problema de regressão pode ser visto como um problema de classificação, já que um valor entre 0 a 1 pode ser interpretado como uma probabilidade, a probabilidade da entrada corresponder a uma certa classe.\n",
    "\n",
    "Para vermos como lidamos com um problema de classificação usando regressores logísticos, vamos usar a coleção Irís. Nesta coleção, o objetivo é classificar uma flor representada por 4 atributos (largura e comprimento da pétala, largura e comprimento do sepal) em 3 classes que correspondem à espécie da flor (_setosa_, _versicolor_ e _virginica_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquie temos um exemplo de 5 flores representadas por 4 atributos (largura e comprimento da pétala, largura e comprimento do sepal):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris['data'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir a classe dessas 5 instâncias: 0, que eu acho que é _setosa_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris['target'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o problema ser resolvido, vamos precisar de um modelo de regressão para cada classe. Assim, para um problema de $t$ = 3 classes, precisamos ter três valores reais, um para cada regressor. Desta forma, os valores reais serão definidos como vetores de tamanho $t$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_X, iris_y = iris['data'], iris['target']\n",
    "# obtem hot-vectors associados com target\n",
    "iris_y = pd.get_dummies(iris_y).values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como antes, vamos normalizar a entrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_X = (iris_X - np.mean(iris_X, axis = 0)) / np.std(iris_X, axis = 0)\n",
    "iris_X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos dividir a coleção em treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separa treino e teste\n",
    "trainX, testX, trainY, testY = train_test_split(iris_X, \n",
    "                                                iris_y, \n",
    "                                                test_size=0.33, \n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de escrever o código completo do regressor, lembre que temos que incorporar os biases no peso. Fazemos isso incorporando um vetor de 1's na entrada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.hstack((np.ones((iris_X.shape[0], 1)), iris_X))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contudo, desta vez, vamos fazer isso dentro do código, como abaixo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# codigo mais simples -- mudando o gdtf3\n",
    "def gdlog_tf(X, Y, n_epochs = 100, lrating = 0.1):\n",
    "    # supoe que bias nao foi incorporado -- entao coloca\n",
    "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "    \n",
    "    m, n = X.shape\n",
    "    _, t = Y.shape # number of targets\n",
    "    \n",
    "    X = tf.constant(X, dtype = tf.float32, name = \"X\")\n",
    "    Y = tf.constant(Y, dtype = tf.float32, name = \"Y\")\n",
    "    W = tf.Variable(tf.random_uniform([n, t], -1.0, 1.0), name = \"W\")\n",
    "    \n",
    "    Yhat = tf.nn.sigmoid(tf.matmul(X, W, name = \"predictions\"))\n",
    "    #loss = tf.reduce_mean(tf.square(Yhat - Y), name = \"loss\")\n",
    "    loss = tf.nn.l2_loss(Yhat - Y, name=\"squared_error_cost\")\n",
    "    \n",
    "    otimizador = tf.train.GradientDescentOptimizer(learning_rate = lrating)\n",
    "    training = otimizador.minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as s:\n",
    "        s.run(init)\n",
    "        for e in range(n_epochs):\n",
    "            _, W_e, loss_e = s.run([training, W, loss])\n",
    "            if e%200==0:\n",
    "                print(loss_e)\n",
    "    return W_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testarmos, vamos inicialmente treinar o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W = gdlog_tf(trainX, trainY, n_epochs=3000)\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E obter previsões com o mesmo, usando o conjunto de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pred(W, testX):\n",
    "    # get test predictions\n",
    "    sigmoid = lambda x: 1. / (1. + np.exp(-x))\n",
    "    return sigmoid(np.matmul(testX, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para avaliarmos o que foi feito, precisamos incorporar o bias na entrada e contar quantos casos foram classificados corretamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# incorporate bias to test\n",
    "Xt = np.hstack((np.ones((testX.shape[0], 1)), testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(pred, testY):\n",
    "    # calculate accuracy\n",
    "    acc = float(sum(np.equal(np.argmax(pred, 1), np.argmax(testY, 1))))/len(pred)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate(get_pred(W, Xt), testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que podemos modificar um pouco a estratégia de avaliação para tratar as saídas do regressor como uma probabilidade normalizada. Desta forma, podemos ver quanta dúvida ele teve em cada flor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = get_pred(W, Xt)\n",
    "# normalize cada linha entre 0 e 1 --> softmax, ou seja, sigmoids normalizadas\n",
    "pred = np.divide(pred, np.reshape(np.sum(pred, axis = 1), (-1, 1)))\n",
    "for i in range(5):\n",
    "    print('P: %.2f %.2f %.2f  R: %d %d %d'%(pred[i, 0], pred[i, 1], pred[i, 2], \n",
    "                                     testY[i, 0], testY[i, 1], testY[i, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo acima, note que houve bastante dúvida na classificação da 3a flor, entre as classes 1 (40%) e 2 (60%). Ele corretamente escolher a classe 2. Se modificarmos nossa função de estimativa para incorporar esta normalização, temos a função softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(W, testX):\n",
    "    # get test predictions\n",
    "    sigmoid = lambda x: 1. / (1. + np.exp(-x))\n",
    "    pred = sigmoid(np.matmul(Xt, W))\n",
    "    return np.divide(pred, np.reshape(np.sum(pred, axis = 1), (-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate(softmax(W, Xt), testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E acabamos de implementar nossa primeira rede neural!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
