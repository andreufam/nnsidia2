{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais Recorrentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "def plot_figs(lst):\n",
    "    if len(lst) == 1:\n",
    "        plt.matshow(lst[0], cmap = 'gray', interpolation='nearest')\n",
    "    else:\n",
    "        f, axes = plt.subplots(1, len(lst))\n",
    "        for i, a in enumerate(axes):\n",
    "            a.matshow(lst[i], cmap = 'gray', interpolation='nearest')\n",
    "            a.set(aspect='equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uma RNN manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN - Recurrent Neural Networks são redes neurais em que os neurônios tem como entrada a sua saída. Desta forma, eles podem formar memórias.\n",
    "\n",
    "Na prática, elas são implementadas como uma arquitetura copiada múltiplas vezes. Há tantas cópias quantas são os instantes de tempo representados no treino. A saída de cada cópia é entrada para a próxima cópia. O exemplo abaixo descreve uma RNN com 3 neurônios de entrada e cinco de saída em uma célula RNN (ou seja, em um instante do tempo). Supondo que temos treinos com 2 instantes de tempo, a rede teria duas céculas, como no diagrama abaixo: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rnn0.png\" alt=\"Exemplo de RNN\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta rede pode ser representada da seguinte forma em tensorflow: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons], dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons,n_neurons], dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00664975  0.19543903  0.08291762  0.08832357 -0.1452561 ]\n",
      " [ 0.32749006 -0.09047262 -0.3080786   0.20217195 -0.4571744 ]\n",
      " [ 0.5958438  -0.3622101  -0.61687875  0.31080633 -0.68643117]\n",
      " [ 0.77524525 -0.58375096 -0.8080832   0.4118852  -0.83014977]]\n",
      "[[ 0.83347845 -0.46762687 -0.8774375   0.15186386 -0.87976223]\n",
      " [ 0.91412014 -0.5418827  -0.82953316 -0.377425   -0.9579276 ]\n",
      " [ 0.95737094 -0.68740857 -0.8081518  -0.65423906 -0.98491126]\n",
      " [ 0.97921664 -0.83296067 -0.8362062  -0.75839305 -0.9942514 ]]\n"
     ]
    }
   ],
   "source": [
    "# t = 0\n",
    "X0_batch = np.array([[0.0, 0.1, 0.2],   # instance 0\n",
    "                     [0.3, 0.4, 0.5],   # instance 1\n",
    "                     [0.6, 0.7, 0.8],   # instance 2\n",
    "                     [0.9, 1.0, 1.1]])  # instance 3\n",
    "# t = 1\n",
    "X1_batch = np.array([[1.1, 1.2, 1.3], \n",
    "                     [1.4, 1.5, 1.6], \n",
    "                     [1.7, 1.8, 1.9], \n",
    "                     [2.0, 2.1, 2.2]]) \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})\n",
    "    \n",
    "print(Y0_val)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rede acima pode ser redefinida usando as funções `BasicRNNCell` e `static_rnn`. Note que neste caso, a função retorna tanto as saídas da rede quanto o estado final dela que, neste caso, corresponde a saída para o último intervalo de tempo (o mesmo que `Y1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, [X0, X1],\n",
    "                                                dtype=tf.float32)\n",
    "Y0, Y1 = output_seqs\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03175795 -0.03413978 -0.07811595 -0.17084466  0.05769194]\n",
      " [ 0.2647824  -0.1855583  -0.09740025 -0.39423943  0.23090008]\n",
      " [ 0.4705062  -0.3286492  -0.11661167 -0.57908356  0.39061368]\n",
      " [ 0.6352659  -0.45809147 -0.13573624 -0.7188958   0.5298294 ]]\n",
      "[[ 0.6560341  -0.55838895 -0.17331886 -0.7907961   0.6223338 ]\n",
      " [ 0.74668574 -0.7433905  -0.21191065 -0.88804203  0.7498099 ]\n",
      " [ 0.819032   -0.85158527 -0.25492802 -0.9409765   0.8342795 ]\n",
      " [ 0.87409574 -0.9107835  -0.3030455  -0.96864784  0.88883334]]\n"
     ]
    }
   ],
   "source": [
    "# t = 0\n",
    "X0_batch = np.array([[0.0, 0.1, 0.2],   # instance 0\n",
    "                     [0.3, 0.4, 0.5],   # instance 1\n",
    "                     [0.6, 0.7, 0.8],   # instance 2\n",
    "                     [0.9, 1.0, 1.1]])  # instance 3\n",
    "# t = 1\n",
    "X1_batch = np.array([[1.1, 1.2, 1.3], \n",
    "                     [1.4, 1.5, 1.6], \n",
    "                     [1.7, 1.8, 1.9], \n",
    "                     [2.0, 2.1, 2.2]]) \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})\n",
    "    \n",
    "print(Y0_val)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No último exemplo, ainda tivemos que criar uma entrada para cada instante de tempo. A seguir, vamos automatizar isso também:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "n_steps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "# get list of n_steps tensors with shape [None, n_inputs]\n",
    "Xseqs = tf.unstack(tf.transpose(X, perm = [1, 0, 2]))\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, Xseqs,\n",
    "                                                dtype=tf.float32)\n",
    "# merge outputs and get final shape (batches, steps, outputs)\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm = [1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.04925115 -0.08284049  0.04345951  0.07417858 -0.04935264]\n",
      "  [-0.31003428 -0.653252    0.2975074   0.7708711  -0.7909568 ]]\n",
      "\n",
      " [[-0.10946348 -0.27015626  0.10460903  0.315636   -0.30657732]\n",
      "  [-0.44478965 -0.74545705  0.48641342  0.8705064  -0.9062193 ]]\n",
      "\n",
      " [[-0.16888303 -0.4390344   0.16497768  0.522135   -0.5256635 ]\n",
      "  [-0.5563627  -0.81515384  0.6256428   0.92795974 -0.95731807]]\n",
      "\n",
      " [[-0.22709988 -0.58170485  0.22413501  0.68141353 -0.69185454]\n",
      "  [-0.64439976 -0.8667141   0.7194453   0.9599478  -0.9795282 ]]]\n"
     ]
    }
   ],
   "source": [
    "# t = 0\n",
    "X_batch = np.array([[[0.0, 0.1, 0.2], [1.1, 1.2, 1.3]],   # instance 0\n",
    "                    [[0.3, 0.4, 0.5], [1.4, 1.5, 1.6]],   # instance 1\n",
    "                    [[0.6, 0.7, 0.8], [1.7, 1.8, 1.9]],   # instance 2\n",
    "                    [[0.9, 1.0, 1.1], [2.0, 2.1, 2.2]]])  # instance 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    out_vals = sess.run(outputs, feed_dict={X: X_batch})\n",
    "    \n",
    "print(out_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desdobramento dinâmico no tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na prática, contudo, o tensorflow pode poupar todo o trabalho de transposições e mudanças de formas necessárias antes, se usarmos `dynamic_rnn`. De fato, neste caso, o grafo com todas as células para todos instantes no tempo não é realmente criado. O algoritmo usa um laço e controla o processo de atualização de pesos sem consumir tanta memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "n_steps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.12536903  0.13399065  0.06619322  0.14388642 -0.00558078]\n",
      "  [-0.8059542   0.8031025   0.5078612   0.9504994   0.03800523]]\n",
      "\n",
      " [[-0.34022027  0.37258416  0.2275392   0.5296505   0.02574121]\n",
      "  [-0.9282176   0.87433124  0.43983948  0.9863469  -0.02313488]]\n",
      "\n",
      " [[-0.52458966  0.57034886  0.3772894   0.7756776   0.05701271]\n",
      "  [-0.9695717   0.92235357  0.39642462  0.9957257  -0.12818918]]\n",
      "\n",
      " [[-0.6701199   0.71855885  0.5096064   0.9013169   0.08817277]\n",
      "  [-0.98487884  0.9527805   0.3875124   0.9985012  -0.2507346 ]]]\n"
     ]
    }
   ],
   "source": [
    "# t = 0\n",
    "X_batch = np.array([[[0.0, 0.1, 0.2], [1.1, 1.2, 1.3]],   # instance 0\n",
    "                    [[0.3, 0.4, 0.5], [1.4, 1.5, 1.6]],   # instance 1\n",
    "                    [[0.6, 0.7, 0.8], [1.7, 1.8, 1.9]],   # instance 2\n",
    "                    [[0.9, 1.0, 1.1], [2.0, 2.1, 2.2]]])  # instance 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    out_vals = sess.run(outputs, feed_dict={X: X_batch})\n",
    "    \n",
    "print(out_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulando sequências com tamanho variável"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em todos os exemplos acima, nossas entradas tinham o mesmo tamanho. Em muitos problemas, este não é o caso. Por exemplo, em classificação de tweets, cada tweet pode ter um tamanho variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "n_steps = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se a RNN vai receber sequências de tamanhos diferentes, é necessário informar a lista dos tamanhos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "seq_lens = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32,\n",
    "                                   sequence_length = seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E, na entrada, as sequências que tem tamanho menor _tem que ser dadas como zero (padding)_ nos intervalos de tempo que não irão aparecer. Por exemplo, supondo que em nosso exemplo anterior, a segunda instância fosse observada apenas no tempo 0 (sequência de tamanho 1), teríamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.02039886  0.12444817  0.16943736 -0.07733408  0.02524563]\n",
      "  [ 0.71817917  0.8689182   0.96358705 -0.47136068  0.27398974]]\n",
      "\n",
      " [[ 0.22861032  0.41079223  0.60151577 -0.22463728  0.09068716]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.41781637  0.6339729   0.8396396  -0.3623429   0.15535478]\n",
      "  [ 0.94111234  0.9610417   0.9878238  -0.4541795   0.49308285]]\n",
      "\n",
      " [[ 0.57660687  0.7854718   0.9407328  -0.4858594   0.21871774]\n",
      "  [ 0.96774274  0.9768544   0.99471605 -0.5186595   0.54894686]]]\n"
     ]
    }
   ],
   "source": [
    "# t = 0\n",
    "X_batch = np.array([[[0.0, 0.1, 0.2], [1.1, 1.2, 1.3]],   # instance 0\n",
    "                    [[0.3, 0.4, 0.5], [0, 0, 0]],         # instance 1 -- padding\n",
    "                    [[0.6, 0.7, 0.8], [1.7, 1.8, 1.9]],   # instance 2\n",
    "                    [[0.9, 1.0, 1.1], [2.0, 2.1, 2.2]]])  # instance 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    out_vals, state_vals = sess.run([outputs, states], \n",
    "                        feed_dict={X: X_batch, seq_lens: [2,1,2,2]})\n",
    "    \n",
    "print(out_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que as saídas para o tempo 2 para a segunda instância são zero. Além disso, observe que o estado final da segunda instância corresponde, de fato, ao seu valor no tempo 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71817917  0.8689182   0.96358705 -0.47136068  0.27398974]\n",
      " [ 0.22861032  0.41079223  0.60151577 -0.22463728  0.09068716]\n",
      " [ 0.94111234  0.9610417   0.9878238  -0.4541795   0.49308285]\n",
      " [ 0.96774274  0.9768544   0.99471605 -0.5186595   0.54894686]]\n"
     ]
    }
   ],
   "source": [
    "print(state_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o caso em que a saída tem tamanho variável, o reconhecimento do fim prematuro será modelado na própria rede. Por exemplo, em tradução, a rede deve emitir uma frase com um número não previamente conhecido de palavras. Assim, a rede deve emitir cada palavra e, quando considerar pertinente, ela emite uma palavra especial que indica _fim de frase_. Ao analisar a saída da rede, são consideradas apenas as palavras observadas antes de _fim de frase_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O mesmo código em Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 2, 3)              0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 2, 5)              45        \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Recurrent Neural Network\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, SimpleRNN\n",
    "\n",
    "# time_steps, input_length\n",
    "visible = Input(shape=(2, 3))\n",
    "# return_sequences = False (default): output.shaep is (5), ie, output from last timestep\n",
    "# return_sequences = True: output.shaep is (2, 5), ie, output from all timesteps; \n",
    "output = SimpleRNN(5, return_sequences = True)(visible)\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificando MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia de classificar as imagens da MNIST usando uma RNN consiste em considerar que cada imagem é formada por uma sequência de linhas de pixels, cada linha vista em um instante de tempo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 28\n",
    "n_inputs = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-ae9b31cef56d>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data\")\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos construir uma rede em que cada célula RNN tem 150 neurônios. O estado final da RNN (um código com 150 valores) então será entrada para uma rede densa com dez neurônios agregados via softmax, como ilustrado abaixo (nós vermelhos com dimensão 28, verdes com dimensão 150 e azul com dimensão 10; 28 desdobramentos no tempo). \n",
    "\n",
    "<img src=\"images/rnn1.png\" alt=\"Exemplo de RNN\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neurons = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 13,910\n",
      "Trainable params: 13,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Recurrent Neural Network\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, SimpleRNN\n",
    "\n",
    "# time_steps, input_length\n",
    "visible = Input(shape=(n_steps, n_inputs))\n",
    "hidden = SimpleRNN(n_neurons, return_sequences = False)(visible)\n",
    "output = Dense(n_outputs, activation = 'softmax')(hidden)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "\n",
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_images = mnist.train.images.reshape((55000, 28, 28))\n",
    "train_labels = to_categorical(mnist.train.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos treinar a nossa rede usando batches de 150 instâncias: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "49500/49500 [==============================] - 11s 220us/step - loss: 0.5781 - acc: 0.8248 - val_loss: 0.2564 - val_acc: 0.9262\n",
      "Epoch 2/10\n",
      "49500/49500 [==============================] - 10s 209us/step - loss: 0.2573 - acc: 0.9235 - val_loss: 0.2243 - val_acc: 0.9336\n",
      "Epoch 3/10\n",
      "49500/49500 [==============================] - 10s 207us/step - loss: 0.2047 - acc: 0.9399 - val_loss: 0.1472 - val_acc: 0.9595\n",
      "Epoch 4/10\n",
      "49500/49500 [==============================] - 10s 209us/step - loss: 0.1689 - acc: 0.9502 - val_loss: 0.1422 - val_acc: 0.9573\n",
      "Epoch 5/10\n",
      "49500/49500 [==============================] - 10s 208us/step - loss: 0.1559 - acc: 0.9544 - val_loss: 0.1367 - val_acc: 0.9618\n",
      "Epoch 6/10\n",
      "49500/49500 [==============================] - 10s 206us/step - loss: 0.1395 - acc: 0.9584 - val_loss: 0.1036 - val_acc: 0.9705\n",
      "Epoch 7/10\n",
      "49500/49500 [==============================] - 10s 206us/step - loss: 0.1261 - acc: 0.9626 - val_loss: 0.1113 - val_acc: 0.9680\n",
      "Epoch 8/10\n",
      "49500/49500 [==============================] - 10s 205us/step - loss: 0.1192 - acc: 0.9652 - val_loss: 0.1304 - val_acc: 0.9653\n",
      "Epoch 9/10\n",
      "49500/49500 [==============================] - 10s 209us/step - loss: 0.1099 - acc: 0.9678 - val_loss: 0.1120 - val_acc: 0.9671\n",
      "Epoch 10/10\n",
      "49500/49500 [==============================] - 10s 208us/step - loss: 0.1049 - acc: 0.9685 - val_loss: 0.1006 - val_acc: 0.9715\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 150\n",
    "history = model.fit(train_images, train_labels, epochs = n_epochs, \n",
    "                    batch_size = batch_size, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "E em tensorflow puro?\n",
    "\n",
    "```python\n",
    "reset_graph()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "logits = tf.layers.dense(states, n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                          logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.nn.in_top_k(logits, y, 1), \n",
    "                                  tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "```\n",
    "\n",
    "Treinamento com batches de 150 instâncias: \n",
    "\n",
    "```python\n",
    "with tf.Session() as s:\n",
    "    init.run()\n",
    "    for e in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            s.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print '%d - accuracy tr: %.6f test: %.6f' % (e, acc_train, acc_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificando MNIST com uma RNN de 2 camadas\n",
    "\n",
    "Vamos agora modificar nossa RNN para suportar 2 camadas, como no diagrama a seguir:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rnn1multi.png\" alt=\"Exemplo de RNN\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar múltiplas camadas em uma RNN com Keras basta empilhá-las. É claro, desta vez, cada camada anterior deve fornecer tanto saídas quanto estados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 28, 100)           12900     \n",
      "_________________________________________________________________\n",
      "simple_rnn_6 (SimpleRNN)     (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 34,010\n",
      "Trainable params: 34,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# time_steps, input_length\n",
    "visible = Input(shape=(n_steps, n_inputs))\n",
    "h1 = SimpleRNN(n_neurons, return_sequences = True)(visible)\n",
    "h2 = SimpleRNN(n_neurons, return_sequences = False)(h1)\n",
    "output = Dense(n_outputs, activation = 'softmax')(h2)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "\n",
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "49500/49500 [==============================] - 21s 415us/step - loss: 0.4621 - acc: 0.8575 - val_loss: 0.2015 - val_acc: 0.9435\n",
      "Epoch 2/10\n",
      "49500/49500 [==============================] - 20s 395us/step - loss: 0.1820 - acc: 0.9449 - val_loss: 0.1549 - val_acc: 0.9531\n",
      "Epoch 3/10\n",
      "49500/49500 [==============================] - 19s 392us/step - loss: 0.1374 - acc: 0.9585 - val_loss: 0.1183 - val_acc: 0.9645\n",
      "Epoch 4/10\n",
      "49500/49500 [==============================] - 20s 395us/step - loss: 0.1225 - acc: 0.9631 - val_loss: 0.1213 - val_acc: 0.9656\n",
      "Epoch 5/10\n",
      "49500/49500 [==============================] - 19s 388us/step - loss: 0.1065 - acc: 0.9683 - val_loss: 0.0917 - val_acc: 0.9753\n",
      "Epoch 6/10\n",
      "49500/49500 [==============================] - 19s 393us/step - loss: 0.0984 - acc: 0.9706 - val_loss: 0.0924 - val_acc: 0.9738\n",
      "Epoch 7/10\n",
      "49500/49500 [==============================] - 20s 396us/step - loss: 0.0904 - acc: 0.9732 - val_loss: 0.0771 - val_acc: 0.9782\n",
      "Epoch 8/10\n",
      "49500/49500 [==============================] - 20s 398us/step - loss: 0.0818 - acc: 0.9756 - val_loss: 0.0825 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      "49500/49500 [==============================] - 19s 393us/step - loss: 0.0819 - acc: 0.9753 - val_loss: 0.1097 - val_acc: 0.9673\n",
      "Epoch 10/10\n",
      "49500/49500 [==============================] - 19s 393us/step - loss: 0.0805 - acc: 0.9755 - val_loss: 0.0854 - val_acc: 0.9764\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs = n_epochs, \n",
    "                    batch_size = batch_size, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note contudo que nossa arquitetura anterior não corresponde exatamente ao diagrama dado, uma vez que a decisão final da rede depende apenas do último estado da última camada. No diagrama, ao contrário, ela depende dos estados finais das duas camadas. Agora que a rede tem tantos estados finais quanto camadas, a representação a ser fornecida para a rede densa pode envolver qualquer agregação dos estados finais. Abaixo, fornecemos uma representação precisa do diagrama dado, modelando a decisão como a concatenação dos estados finais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Lambda\n",
    "\n",
    "# time_steps, input_length\n",
    "visible = Input(shape=(n_steps, n_inputs))\n",
    "h1 = SimpleRNN(n_neurons, return_sequences = True)(visible)\n",
    "h2 = SimpleRNN(n_neurons, return_sequences = False)(h1)\n",
    "h1_last = Lambda(lambda x: x[:,-1,:])(h1)\n",
    "merge = Concatenate()([h1_last, h2])\n",
    "output = Dense(n_outputs, activation = 'softmax')(merge)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um detalhe importante desta implementação é o uso de uma camada Lambda do Keras. Ela permite que do tensor de entrada h1 (com shape (batch_size, n_layers, n_neurons)) sejam obtidos apenas os estados da última camada (ou seja, x[:, -1, :] para x correspondendo ao valor de h1). O estado obtido (h1_last) é concatenado com o estado final da última camada (h2) e dado como entrada para a camada densa. Camadas Lambda permitem que transformações arbitrárias sejam executadas sobre os dados fluindo entre as camadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 28, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_7 (SimpleRNN)        (None, 28, 100)      12900       input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 100)          0           simple_rnn_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_8 (SimpleRNN)        (None, 100)          20100       simple_rnn_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200)          0           lambda_1[0][0]                   \n",
      "                                                                 simple_rnn_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           2010        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 35,010\n",
      "Trainable params: 35,010\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "49500/49500 [==============================] - 17s 336us/step - loss: 0.4382 - acc: 0.8655 - val_loss: 0.1799 - val_acc: 0.9458\n",
      "Epoch 2/10\n",
      "49500/49500 [==============================] - 15s 312us/step - loss: 0.1837 - acc: 0.9450 - val_loss: 0.1290 - val_acc: 0.9627\n",
      "Epoch 3/10\n",
      "49500/49500 [==============================] - 15s 309us/step - loss: 0.1382 - acc: 0.9590 - val_loss: 0.1058 - val_acc: 0.9695\n",
      "Epoch 4/10\n",
      "49500/49500 [==============================] - 15s 310us/step - loss: 0.1237 - acc: 0.9630 - val_loss: 0.1018 - val_acc: 0.9718\n",
      "Epoch 5/10\n",
      "49500/49500 [==============================] - 15s 312us/step - loss: 0.1071 - acc: 0.9686 - val_loss: 0.0995 - val_acc: 0.9720\n",
      "Epoch 6/10\n",
      "49500/49500 [==============================] - 15s 312us/step - loss: 0.0949 - acc: 0.9715 - val_loss: 0.1023 - val_acc: 0.9709\n",
      "Epoch 7/10\n",
      "49500/49500 [==============================] - 15s 312us/step - loss: 0.0923 - acc: 0.9722 - val_loss: 0.0857 - val_acc: 0.9736\n",
      "Epoch 8/10\n",
      "49500/49500 [==============================] - 15s 312us/step - loss: 0.0849 - acc: 0.9744 - val_loss: 0.0715 - val_acc: 0.9795\n",
      "Epoch 9/10\n",
      "49500/49500 [==============================] - 15s 312us/step - loss: 0.0801 - acc: 0.9759 - val_loss: 0.0858 - val_acc: 0.9725\n",
      "Epoch 10/10\n",
      "49500/49500 [==============================] - 16s 315us/step - loss: 0.0787 - acc: 0.9760 - val_loss: 0.0727 - val_acc: 0.9807\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs = n_epochs, \n",
    "                    batch_size = batch_size, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prevendo séries de tempo\n",
    "### Um modelo $n \\times n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um dos problemas mais comuns em aprendizado de sequência/temporal é previsão de séries de tempo. Neste caso, dada um evento no tempo, o modelo deve prever o resultado do evento no tempo seguinte. Vamos tomar como exemplo o número de passageiros mensal nos EUA entre 1949 e 1961:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "airline = pd.read_csv('data/airline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengers</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>1949-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "      <td>1949-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132</td>\n",
       "      <td>1949-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129</td>\n",
       "      <td>1949-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>1949-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengers        date\n",
       "0         112  1949-01-01\n",
       "1         118  1949-02-01\n",
       "2         132  1949-03-01\n",
       "3         129  1949-04-01\n",
       "4         121  1949-05-01"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(airline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1516a3c7160>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1516bc57128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series = airline['passengers']\n",
    "series.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora preparar a série para supervisão. A idéia é que cada quantidade de passageiros em um certo momento no tempo seja uma variável útil para prever a quantidade no próximo momento no tempo. Vamos usar a operação shift() do pandas para isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data(series, target, lag = 1):\n",
    "    # transfor to supervised learning\n",
    "    series = series.iloc[1:]\n",
    "    series = pd.concat([series.shift(1), series], axis = 1)\n",
    "    series.fillna(0, inplace=True)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengers</th>\n",
       "      <th>passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118.0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132.0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129.0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>121.0</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengers  passengers\n",
       "1         0.0         118\n",
       "2       118.0         132\n",
       "3       132.0         129\n",
       "4       129.0         121\n",
       "5       121.0         135"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised = transform_data(series, 'passengers')\n",
    "supervised_values = supervised.values\n",
    "supervised.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos separar os dados em treino e teste, onde o teste corresponde ao horizonte de tempo para o qual prentendemos fazer previsões. Por exemplo, vamos considerar um horizonte de 40 meses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "horizon = 40\n",
    "train, test = supervised_values[0:-horizon], supervised_values[-horizon:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de iniciar qualquer previsão, os dados devem ser escalados. Aqui vamos usar uma escala simples para colocar os dados entre -1 e 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "    new_row = [x for x in X] + [value]\n",
    "    array = np.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler, train_scaled, test_scaled = scale(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -0.92286501],\n",
       "       [-0.49247312, -0.84573003],\n",
       "       [-0.43225806, -0.86225895],\n",
       "       [-0.44516129, -0.90633609]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.21290323, -0.37190083])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled[:, 0:-1].shape\n",
    "train_scaled[40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez escalados os dados, podemos treinar a RNN. Neste caso, vamos usar células LSTM. Em particular, consideramos que cada entrada tenha batch_size = 1, se refira a apenas 1 passo de tempo e tem entrada de comprimento 1 (ou seja, se refere a uma única quantidade de passageiros e nenhuma informação adicional). Como este problema é simples, serão usadas células LSTM com apenas 4 blocos.\n",
    "\n",
    "Como queremos que as células lembrem do estado da computação deixada pelo último batch da época atual, deixamos stateful = True. Assim, mesmo embora a entrada tenha apenas 1 passo de tempo, a rede vai ser influenciada por tantos passos de tempo quanto forem os batches processados ao longo da época. Para isso, vamos treinar cada época por vez, executando os batches na ordem temporal (ou seja, shuffle = False). Como a rede é _stateful_, o estado de um batch é enviado ao próximo até que todos tenham sido processados. Neste ponto, reiniciamos o estado da rede, antes de começar uma nova época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM\n",
    "\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    \n",
    "    visible = Input(batch_shape=(batch_size, X.shape[1], X.shape[2]))\n",
    "    hidden = LSTM(neurons, stateful=True)(visible)\n",
    "    output = Dense(1)(hidden)\n",
    "    model = Model(inputs = visible, outputs = output)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, \n",
    "                  verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, treinamos nossa LSTM para 100 épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "103/103 [==============================] - 2s 17ms/step - loss: 0.2781\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.1523\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.1015\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0837\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0752\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0695\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0651\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0616\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0588\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0564\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0544\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0526\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0511\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0497\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0485\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0474\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0464\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0454\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0446\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0438\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0430\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0423\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0416\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0409\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0403\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0397\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0391\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0385\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0379\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0374\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0368\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0363\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0358\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0353\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0349\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0344\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0340\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0336\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0331\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0327\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0323\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0320\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0316\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0312\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0309\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0306\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0302\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0299\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0296\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0293\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0291\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0288\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0285\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0283\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0280\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0278\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0276\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0273\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0271\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0269\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0267\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0265\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0263\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0261\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0260\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0258\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0256\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0255\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0253\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0251\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0250\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0248\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0247\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0246\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 8ms/step - loss: 0.0244\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0243\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0242\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0240\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0239\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0238\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0237\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0236\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0235\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0234\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0233\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0232\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0231\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0230\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0229\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0228\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0227\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0227\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0226\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0225\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0224\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0224\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0223\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0222\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0222\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0221\n"
     ]
    }
   ],
   "source": [
    "lstm_model = fit_lstm(train_scaled, 1, 100, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos usar o modelo para prever a série. Para cada elemento do conjunto de teste (X), o modelo prevê o próximo valor (yhat). O valor previsto yhat é corrigido em escala e adicionado ao conjunto de previsões:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    yhat = model.predict(X, batch_size=batch_size)\n",
    "    return yhat[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(len(test_scaled)):\n",
    "    # make one-step forecast\n",
    "    X = test_scaled[i, 0:-1] \n",
    "    yhat = forecast_lstm(lstm_model, 1, X)\n",
    "    # invert scaling\n",
    "    yhat = invert_scale(scaler, X, yhat)\n",
    "    # store forecast\n",
    "    predictions += [yhat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O desempenho final obtido pode ser medido em termos de RMSE e observado graficamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 56.909\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(series.values[-horizon:], predictions))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Time')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEXCAYAAACjyo8UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBDna0Ws0Gk2Q87+14l8JwPJrsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x151675ec358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Test for horizon = \" + str(horizon), fontsize=14)\n",
    "plt.plot(series.values[-horizon:], \"-\", markersize=5)\n",
    "plt.plot(series.values[-horizon:], \"bo\", markersize=5, label=\"real\")\n",
    "plt.plot(predictions, \"-\", markersize=10)\n",
    "plt.plot(predictions, \"r*\", markersize=10, label=\"prediction\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Material derivado do livro _Handson Machine Learning with Scikit-learn and Tensorflow_, de Aurélian Géron. A aula sobre Keras usado como previsor de séries de tempo foi baseada no material de Jason Browlee, disponível em https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
