{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dAQKRt2QVszq"
   },
   "source": [
    "#  LSTMs/GRUs e a CTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRviJ-oBVszr"
   },
   "source": [
    "Até agora, usamos células em RNNs que consistiam de neurônios artificiais tradicionais. Agora, vamos passar a usar células que implementam memória de um ponto de vista funcional. Elas podem ser usadas no lugar de qualquer célula/unidade tradicional de uma RNN, sendo responsável por ler, escrever ou lembrar de informação fluindo no modelo. \n",
    "\n",
    "A LSTM, em particular, consiste basicamente de uma unidade linear (a celula de informação propriamente dita) envoltas por três portas lógicas, responsáveis pela manutenção dos dados. Uma é responsável por permitir que dados fluam para a célulade informação (entrada), uma pela saída da célula e a última é responável por lembrar ou esquecer de dados de acordo com as necessidades da rede. A GRU é uma versão mais simplificada da LSTM. Ela combina portas da LSTM em menos portas, produzindo um modelo menor.\n",
    "\n",
    "Estas unidades ajuam a resolver o problema de manter estados, porque a rede pode escolher esquecê-los se já não servem mais. Desta forma, o problema dos gradientes é menos importantes com LSTMs e GRUs. De fato, LSTMs e GRUs são tão convenientes que, na prática, pouco se usam RNNs com células que não sejam estas.\n",
    "\n",
    "Nesta aula, vamos usar LSTMs em problemas de reconhecimento de escrita.\n",
    "\n",
    "### Arquitetura Long Short-Term Memory \n",
    "\n",
    "Neste texto, vamos considerar que uma LSTM é formada por três portas lógicas: \"Input\" ou \"Write\", responsável pela escrita na LSTM de dados vindos do resto da RNN; \"Output\" ou \"Read\", responsável pela saída da LSTM para o resto da RNN; e \"Keep\" ou \"Forget\", rsponsável pela manutenção ou modificação de dados armazenados na LSTM.\n",
    "\n",
    "<img src=https://ibm.box.com/shared/static/zx10duv5egw0baw6gh2hzsgr8ex45gsg.png width=\"720\"/>\n",
    "<center>*Diagrama de uma Long Short-Term Memory Unit*</center>\n",
    "\n",
    "Se você estiver mais interssado em saber sobre LSTMs e suas variantes, incluindo GRUs, leia o blog: http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3AqDncHQVszs"
   },
   "source": [
    "# Connectionist Temporal Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqijIyQHVszs"
   },
   "source": [
    "Um típico pipeline de reconhecimento temporal, em deep learning, envolve uma rede neural para reconhecimento combinada com algum mecanismo que garanta a consistência no tempo.\n",
    "\n",
    "Por exemplo, na imagem abaixo, temos a representação de uma arquitetura usada em reconhecimento de fala. Nela, os componente neurais (os módulos em azul) são responsáveis por identificar o fonema apartir de algum sinal de entrada (o espectograma, features MEL ou o sinal puro de som, observados em um _frame_ de som). O componente de consistência temporal (no exemplo, a barra roxa que representa a função CTC, mas poderia ser uma HMM), por sua vez, lida com a sequência de possíveis fonemas sendo identificados para entender o que está sendo dito em geral. Em suma, este componente trata do contexto geral.\n",
    "\n",
    "![](images/ctc1.png)\n",
    "\n",
    "Em redes neurais, uma possibilidade para o componente temporal é a função CTC (Connectionist Temporal Classification) proposta por Alex Graves para o problema de reconhecimento de escrita manual (ftp://ftp.idsia.ch/pub/juergen/icml2006.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "90fi8XePVszt"
   },
   "source": [
    "Tomando como exemplo o problema de escrita manual, imagine que o usuário escreveu 'dançar'.\n",
    "\n",
    "![](images/dancar.png)\n",
    "\n",
    "Digamos que o nosso modelo está reconhecendo a terceira letra da palavra como sendo \"u\". Podemos dizer que o modelo está aproximando a probabilidade $p$(${\\bf y}$ = 'u' | ${\\bf x}$ = segmento de imagem correspondente à terceira letra em dançar) como a convicção que a rede neural, que está observando aquele segmento de imagem, tem de se tratar de um 'u'. Contudo, o correto seria 'n', algo que pode ser observado pelo contexto todo da palavra, já que 'dançar' é muito mais provavelmente uma palavra do Português que 'dauçar'.\n",
    "\n",
    "Assim, em vez de aprender uma letra por vez, é melhor aprender a sequência de letras que faz mais sentido.\n",
    "\n",
    "Cada sequência pode ser vista como um caminho (representado por $\\pi$) que passa por cada letra reconhecida em cada instante no tempo (com saída softmax $y_{\\pi_t}$). Assim, a probabilidade de uma sequência observada ao longo de $T$ instantes de tempo pode ser descrita como:\n",
    "\n",
    "$$p(\\pi|{\\bf x}) = \\prod_{t}^{T}{y_{\\pi_t}}$$\n",
    "\n",
    "Ou seja, a probabilidade é dada pelo produto das saídas softmax ao longo de $T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DwIRB6ktVszu"
   },
   "source": [
    "#### Dynamic Time Warping\n",
    "\n",
    "Mas por que precisamos fazer isso? Afinal, uma RNN/LSTM/GRU já não considera seu passado quando emite uma saída? Sim, mas na prática, nem sempre é simples dizer onde começam e terminam segmentos, nem qual o tamanho 'certo' de uma letra, nem mesmo garantir que as entradas não sejam superpostas. Para lidar com estes problemas, temos duas alternativas:\n",
    "\n",
    "* rotular cada instante no tempo e também descrever onde, mais ou menos, começam e terminam as letras -- hmm, não parece algo muito legal de fazer, né?\n",
    "* rotular uma sequência inteira e deixar a rede advinhar como ela se segmenta -- aqui é onde entra a CTC!\n",
    "\n",
    "Dado o rótulo geral $\\ell$ (por exemplo, $\\ell$ = 'dançar' para a imagem acima), a CTC corresponde à estimativa:\n",
    "\n",
    "$$p(\\ell|{\\bf x}) = \\sum_{i}{p(\\ell|\\pi_i) p(\\pi_i|{\\bf x})}$$\n",
    "\n",
    "Ou seja, a probabilidade de se ler 'dançar' é a soma das probabilidades de ver dançar em suas várias formas (ou seja, marginalizada em $\\pi$), sendo cada forma ponderada por sua possibilidade de ocorrer dada a entrada. Esse passo é chamado _dynamic time warping_.\n",
    "\n",
    "Mas como estimar a probabilidade de $p(\\ell|{\\bf x})$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qULZa44xVszv"
   },
   "source": [
    "#### Estimando a probabilidade do rótulo, dada a entrada\n",
    "\n",
    "Para estimar $p(\\ell|{\\bf x})$, vamos usar um algoritmo de programação dinâmica, chamado _forward-backward_. Para compreendê-lo, vamos usar o exemplo dado por Alex Graves em seus artigo sobre a CTC, onde ele decodifica da palavra 'cat'.\n",
    "\n",
    "![](images/ctc-cat-graves.png)\n",
    "\n",
    "Na figura, cada linha corresponde a uma letra ou vazio (branco) e cada coluna corresponde a um instante no tempo em que uma parte daquela letra (por exemplo, uma coluna de pixels da letra) está sendo observada. As setas indicam os caminhos a serem tomados em termos de escolha de rótulos. Há três possibilidades de transição em cada instante do tempo: \n",
    "\n",
    "* permaneço com o rótulo atual (seta para mesma linha) -- ex: em tempo $t$ vi pixels em 'C'; em tempo $t+1$, continuo vendo pixels, que devem ser de 'C' ainda (mas também poderiam ser de uma letra sobreposta ou ligada); \n",
    "* vou para um próximo rótulo (seta para branco) -- ex: em tempo $t$ vi pixels em 'C'; em tempo $t+1$, não vejo mais pixels, o que sugere que 'C' acabou (mas pode não ter acabado -- posso estar apenas vendo o intervalo antes que ela continue, como seria o caso do ideograma 的); e \n",
    "* vou para o próximo rótulo previsto -- ex: em tempo $t$ não vejo pixels; em tempo $t+1$, vejo pixels, o que sugere que deve ser uma letra depois de 'C' (ou uma continuação, como vimos acima). \n",
    "\n",
    "Deste modo, o rótulo $\\ell$ = ['C','A','T'], pode ser visto como $\\ell'$ = [$\\lambda$,'C',$\\lambda$,'A',$\\lambda$,'T',$\\lambda$], onde $\\lambda$ indica um rótulo vazio (branco)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N2gfELqFVszv"
   },
   "source": [
    "A ideia chave para estimar $p(\\ell|{\\bf x})$ é que a soma sobre os caminhos correspondentes a uma rotulação pode ser decomposta em uma soma iterativa correspondente aos prefixos daquela rotulação. Estas iterações podem ser calculadas de forma eficiente com variáveis recursivas $\\alpha$ e $\\beta$ que correspondem ao visto antes e depois do tempo $t$.\n",
    "\n",
    "$$p(\\ell|{\\bf x}) = \\sum_{s=1}^{\\ell'}{\\frac{\\alpha_t(s) \\beta_t(s)}{y^{(t)}_{\\ell'_s}}}$$\n",
    "\n",
    "Note que $\\alpha$ e $\\beta$ dependem da saída $y$ da RNN. Assim, durante o treino, cada novo conjunto de previsões da RNN é avaliado usando $p(\\ell|{\\bf x})$ e os neurônios modificam seus pesos de acordo com o gradiente desta função, dado por: \n",
    "\n",
    "$$\\frac{\\partial p(\\ell|{\\bf x})}{\\partial {y^{(t)}_k}} = \\frac{1}{{y^{(t)}_k}^2} \\sum_{s | \\ell'_s = k}{\\alpha_t(s) \\beta_t(s)}$$\n",
    "\n",
    "Para detalhes sobre a CTC, leia o artigo em http://www.cs.toronto.edu/~graves/icml_2006.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CgsSN11ZVszw"
   },
   "source": [
    "O tensorflow implementa a CTC como `nn.ctc.loss()`. A seguir, temos um exemplo de uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGbBUlTTVszx",
    "outputId": "05256479-c237-4022-affd-3e921f7eabb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#  Compatibility imports\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from six.moves import xrange as range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4GnnCKMKVsz3"
   },
   "source": [
    "Para testarmos a CTC, vamos usar uma pequena coleção de imagens que representam os dígitos de 0 a 9. Cada imagem corresponde a uma sequência aleatória de dígitos de comprimento variável (e número de digitos variáveis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbJw3sBFVsz4"
   },
   "outputs": [],
   "source": [
    "with open('data/test_varlen.pkl', 'rb') as f:\n",
    "    data = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e12t94LoVsz6",
    "outputId": "c2fd3d84-6841-417d-f8c9-357cbe2f6afb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "10\n",
      "instances 100\n",
      "height_0: 9\n",
      "width_0: 38\n"
     ]
    }
   ],
   "source": [
    "print (data['chars'])\n",
    "print (len(data['chars']))\n",
    "print ('instances', len(data['x']))\n",
    "# height and weight for first image\n",
    "print ('height_0:', len(data['x'][0]))\n",
    "print ('width_0:', len(data['x'][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZlu7q2tVsz9"
   },
   "source": [
    "Abaixo, podemos ver as primeiras duas sequências de dígitos, uma com 4 dígitos (38 pixels de largura) e outra com 9 dígitos (em 60 pixels de largura). O rótulo correspondente à primeira sequência indica os dígitos que estão presentes (0, 1, 2 e 3). Para a segunda, são 4, 5, 6, 7, 8, 9, 5, 3 e 7. Todas as imagens na coleção têm 8 pixels de altura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "I9yZrPfKVsz-"
   },
   "outputs": [],
   "source": [
    "slabs = [(np.asarray(data['x'][i]), np.asarray(data['y'][i])) \n",
    "         for i in range(len(data['x']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yh2XIHCkVs0A",
    "outputId": "e1e25836-8776-441a-ed2d-ae5c3d5242ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[4 5 6 7 8 9 5 3 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAByCAYAAABzwTvbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAV4glm/avH09AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x208867e87f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABUCAYAAACiNN3wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqvAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x208888e2320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(slabs[i][1])\n",
    "    plt.figure()\n",
    "    plt.imshow(slabs[i][0], cmap = 'gray', interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JodWbeTWVs0E"
   },
   "source": [
    "A função a seguir lê esta coleção para a memória, fornecendo as sequências, seus rótulos correspondentes e o número de sequências válidas lidas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ig_iofl7Vs0F"
   },
   "outputs": [],
   "source": [
    "# load the training or test dataset from disk\n",
    "def get_toy_data(pname):\n",
    "    with open(pname, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='latin1')\n",
    "    num_examples = len(data['x'])\n",
    "    # note that image shape is modified to columns x lines, since it is expected a\n",
    "    # fixed number of lines and a varying number of columns\n",
    "    seqs = np.asarray([data['x'][t].swapaxes(0, 1) \n",
    "                       for t in range(num_examples) if len(data['y'][t]) > 0])\n",
    "    # get label seqs\n",
    "    labs = np.asarray([np.asarray(data['y'][t]) \n",
    "                       for t in range(num_examples) if len(data['y'][t]) > 0])\n",
    "    return seqs, labs, len(labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nkmODASfVs0G"
   },
   "source": [
    "Note que as sequências são transpostas de forma a serem representadas por tantos intervalos de tempo quanto forem as suas larguras e 8 'atributos de entrada' já que isto corresponde a sua altura em pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WQkjRcBVs0H",
    "outputId": "722346e8-4db1-4fed-a3d7-b5b394dd2b78"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAAD8CAYAAAAc2gjyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLe2utgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20888aa7080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEUAAAD8CAYAAAAhSGmUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20888ad7b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seqs, _, _ = get_toy_data('data/test_varlen.pkl')\n",
    "for i in range(2):\n",
    "    plt.figure()\n",
    "    plt.imshow(seqs[i], cmap = 'gray', interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R5LGtyrjVs0L"
   },
   "source": [
    "A função a seguir é dada apenas por conveniência. Ela permite gerar sequências aleatórias para testar a LSTM que vamos usar. Mas nesta aula vamos usar a coleção toy descrita antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "j8bJ2bFRVs0M"
   },
   "outputs": [],
   "source": [
    "# generate synthetical data for training\n",
    "# useful for testing\n",
    "def fake_data(num_examples, num_features, num_labels, min_size = 10, max_size=100):\n",
    "\n",
    "    # Generating different timesteps for each fake data\n",
    "    timesteps = np.random.randint(min_size, max_size, (num_examples,))\n",
    "\n",
    "    # Generating random input\n",
    "    inputs = np.asarray([np.random.randn(t, num_features).astype(np.float32) for t in timesteps])\n",
    "\n",
    "    # Generating random label, the size must be less or equal than timestep in order to achieve the end of the lattice in max timestep\n",
    "    labels = np.asarray([np.random.randint(0, num_labels, \n",
    "                                           np.random.randint(1, inputs[i].shape[0], (1,))).astype(np.int64) \n",
    "                         for i, _ in enumerate(timesteps)])\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "keeq13adVs0R"
   },
   "source": [
    "Para usar a CTC do tensorflow, precisamos colocar as sequências de entrada no formato esparso usado pela função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kYFMkCYqVs0S"
   },
   "outputs": [],
   "source": [
    "def sparse_tuple_from(sequences, dtype=np.int32):\n",
    "    \"\"\"Create a sparse representention of x.\n",
    "    Args:\n",
    "        sequences: a list of lists of type dtype where each element is a sequence\n",
    "    Returns:\n",
    "        A tuple with (indices, values, shape)\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for n, seq in enumerate(sequences):\n",
    "        indices.extend(zip([n]*len(seq), range(len(seq))))\n",
    "        values.extend(seq)\n",
    "\n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    values = np.asarray(values, dtype=dtype)\n",
    "    shape = np.asarray([len(sequences), np.asarray(indices).max(0)[1]+1], dtype=np.int64)\n",
    "\n",
    "    return indices, values, shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZUE7ztUSVs0X"
   },
   "source": [
    "Por exemplo, duas sequências de entrada, (0, 1, 3) e (5, 8, 9, 3, 2), serão convertidas para a forma I, V, S, onde I corresponde a uma sequência de pares que indicam o índice da sequência e do valor dentro da sequência; V corresponde às observações correspondentes a cada par; S é um par indicando o número de sequências e o número máximos de valores observados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2YRQl0DbVs0X",
    "outputId": "6c47604b-9035-46db-fc59-119fdd42c199"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0],\n",
       "        [0, 1],\n",
       "        [0, 2],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 3],\n",
       "        [1, 4]], dtype=int64),\n",
       " array([0, 1, 3, 5, 8, 9, 3, 2]),\n",
       " array([2, 5], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_tuple_from([[0,1,3], [5,8,9,3,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zL1tZr4ZVs0a"
   },
   "source": [
    "Como as sequências de entrada podem ter tamanho variável, elas precisam ser preenchidas para terem o mesmo tamanho em um certo batch. A função a seguir faz isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BAVzmpl-Vs0c"
   },
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, maxlen=None, dtype=np.float32,\n",
    "                  padding='post', truncating='post', value=0.):\n",
    "    '''Pads each sequence to the same length: the length of the longest sequence.\n",
    "        If maxlen is provided, any sequence longer than maxlen is truncated to\n",
    "        maxlen. Truncation happens off either the beginning or the end\n",
    "        (default) of the sequence. Supports post-padding (default) and\n",
    "        pre-padding.\n",
    "\n",
    "        Args:\n",
    "            sequences: list of lists where each element is a sequence\n",
    "            maxlen: int, maximum length\n",
    "            dtype: type to cast the resulting sequence.\n",
    "            padding: 'pre' or 'post', pad either before or after each sequence.\n",
    "            truncating: 'pre' or 'post', remove values from sequences larger\n",
    "            than maxlen either in the beginning or in the end of the sequence\n",
    "            value: float, value to pad the sequences to the desired value.\n",
    "        Returns\n",
    "            x: numpy array with dimensions (number_of_sequences, maxlen)\n",
    "            lengths: numpy array with the original sequence lengths\n",
    "    '''\n",
    "    lengths = np.asarray([len(s) for s in sequences], dtype=np.int64)\n",
    "\n",
    "    nb_samples = len(sequences)\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    # take the sample shape from the first non empty sequence\n",
    "    # checking for consistency in the main loop below.\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    "\n",
    "    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if len(s) == 0:\n",
    "            continue  # empty list was found\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n",
    "\n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
    "                             (trunc.shape[1:], idx, sample_shape))\n",
    "\n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
    "    return x, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9qBgKJrQVs0e",
    "outputId": "cdbb13a7-40d6-4449-8930-19329be10bbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[1., 2., 0., 0.],\n",
      "       [1., 2., 3., 4.],\n",
      "       [1., 2., 3., 0.]], dtype=float32), array([2, 4, 3], dtype=int64))\n",
      "(array([[0., 0., 1., 2.],\n",
      "       [1., 2., 3., 4.],\n",
      "       [0., 1., 2., 3.]], dtype=float32), array([2, 4, 3], dtype=int64))\n",
      "(array([[1., 2., 0.],\n",
      "       [1., 2., 3.],\n",
      "       [1., 2., 3.]], dtype=float32), array([2, 4, 3], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print (pad_sequences([[1,2],[1,2,3,4],[1,2,3]]))\n",
    "print (pad_sequences([[1,2],[1,2,3,4],[1,2,3]], padding = 'pre'))\n",
    "print (pad_sequences([[1,2],[1,2,3,4],[1,2,3]], maxlen = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "valUVKQUVs0h"
   },
   "source": [
    "Finalmente, temos a nossa rede, usando uma RNN dinâmica com células LSTM na camada oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4s9OaeNDVs0i"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# number de pixel in columns\n",
    "num_features = 9 \n",
    "# total of digits + blank = 11 symbols\n",
    "num_classes = 11\n",
    "\n",
    "# Hyper-parameters\n",
    "num_hidden = 35\n",
    "learning_rate = 1e-2\n",
    "\n",
    "# data\n",
    "ftrain = 'data/train_varlen.pkl'\n",
    "input_seqs, seq_labels, num_examples = get_toy_data(ftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zk07kFpcVs0l"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable rnn/lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-0550b53bc544>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# The second output is the last state and we will no use that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Reshaping to apply the same weights over the timesteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[1;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m         dtype=dtype)\n\u001b[0m\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[1;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[0;32m    826\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       swap_memory=swap_memory)\n\u001b[0m\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m   \u001b[1;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   3230\u001b[0m       \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3231\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[1;32m-> 3232\u001b[1;33m                                     return_same_structure)\n\u001b[0m\u001b[0;32m   3233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3234\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[1;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[0;32m   2950\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2951\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[1;32m-> 2952\u001b[1;33m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[0;32m   2953\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2954\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[1;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2885\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[0;32m   2886\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2887\u001b[1;33m     \u001b[0mbody_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2888\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2889\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m   3199\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[0;32m   3200\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[1;32m-> 3201\u001b[1;33m         \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[1;34m(time, output_ta_t, state)\u001b[0m\n\u001b[0;32m    795\u001b[0m           \u001b[0mcall_cell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcall_cell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m           \u001b[0mstate_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m           skip_conditionals=True)\n\u001b[0m\u001b[0;32m    798\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m       \u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_rnn_step\u001b[1;34m(time, sequence_length, min_sequence_length, max_sequence_length, zero_output, state, call_cell, state_size, skip_conditionals)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;31m# steps.  This is faster when max_seq_len is equal to the number of unrolls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;31m# (which is typical for dynamic_rnn).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m     \u001b[0mnew_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m     \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[0mnew_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 785\u001b[1;33m     \u001b[0mcall_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;31m# method.  See the class docstring for more details.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     return base_layer.Layer.__call__(self, inputs, state, scope=scope,\n\u001b[1;32m--> 329\u001b[1;33m                                      *args, **kwargs)\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m       \u001b[1;31m# Actually call layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m           \u001b[0minput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, inputs_shape)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_depth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m         partitioner=maybe_partitioner)\n\u001b[0m\u001b[0;32m    778\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m       \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_initializer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_variable\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    459\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0madd_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;34m\"\"\"Alias for `add_weight`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m   def add_weight(self,\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m             getter=vs.get_variable)\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, getter)\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m         aggregation=aggregation)\n\u001b[0m\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    533\u001b[0m     new_variable = getter(\n\u001b[0;32m    534\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m         **kwargs_for_getter)\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[1;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1465\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1466\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1467\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1215\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    525\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    479\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[1;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    846\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 848\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    849\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable rnn/lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# e.g: output of a convolutional net\n",
    "# Has size [batch_size, max_stepsize, num_features], but the\n",
    "# batch_size and max_stepsize can vary along each step\n",
    "inputs = tf.placeholder(tf.float32, [None, None, num_features])\n",
    "shape = tf.shape(inputs)\n",
    "batch_s, max_timesteps = shape[0], shape[1]\n",
    "\n",
    "# Here we use sparse_placeholder that will generate a\n",
    "# SparseTensor required by ctc_loss op.\n",
    "targets = tf.sparse_placeholder(tf.int32)\n",
    "\n",
    "# 1d array of size [batch_size]\n",
    "seq_len = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Defining the cell\n",
    "cell = tf.contrib.rnn.LSTMCell(num_hidden, state_is_tuple=True)\n",
    "\n",
    "# The second output is the last state and we will no use that\n",
    "outputs, _ = tf.nn.dynamic_rnn(cell, inputs, seq_len, dtype=tf.float32)\n",
    "\n",
    "# Reshaping to apply the same weights over the timesteps\n",
    "outputs = tf.reshape(outputs, [-1, num_hidden])\n",
    "\n",
    "# W init = truncated normal with mean 0 and stdev=0.1\n",
    "# bias init Zero initialization\n",
    "W = tf.Variable(tf.truncated_normal([num_hidden,\n",
    "                                     num_classes],\n",
    "                                    stddev=0.1))\n",
    "b = tf.Variable(tf.constant(0., shape=[num_classes]))\n",
    "### do not include sigmoid because CTC will do that\n",
    "logits = tf.matmul(outputs, W) + b \n",
    "\n",
    "# Reshaping back to the original shape\n",
    "logits = tf.reshape(logits, [batch_s, -1, num_classes])\n",
    "# Time major\n",
    "logits = tf.transpose(logits, (1, 0, 2))\n",
    "\n",
    "loss = tf.nn.ctc_loss(targets, logits, seq_len)\n",
    "cost = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                       0.9).minimize(cost)\n",
    "\n",
    "# Option 2: tf.nn.ctc_beam_search_decoder (slower but better)\n",
    "decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, seq_len)\n",
    "\n",
    "# Inaccuracy: label error rate\n",
    "ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),\n",
    "                                      targets))\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dl5rNhd1Vs0q"
   },
   "source": [
    "Para avaliar e nossa implementação, vamos usar uma função que usa a RNN para estimar o rótulo de uma sequência de entrada e decodifica a saída da RNN em forma de uma sequência. As sequências são exibidas antes das previstas, de forma a avaliar a RNN, tanto em treino quanto teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8W65rUMHVs0q"
   },
   "outputs": [],
   "source": [
    "def show_decoded_seqs(session, X, Y):\n",
    "    # Padding input to max_time_step of this batch\n",
    "    Xp, seqlen = pad_sequences(X)\n",
    "\n",
    "    # Converting to sparse representation so as to to feed SparseTensor input\n",
    "    Ys = sparse_tuple_from(Y)\n",
    "\n",
    "    # Decoding\n",
    "    d = session.run(decoded[0], \n",
    "                    feed_dict={inputs: Xp,\n",
    "                               targets: Ys,\n",
    "                               seq_len: seqlen})\n",
    "    d_dense = tf.sparse_tensor_to_dense(d, default_value=-1)\n",
    "    dense_decoded = d_dense.eval(session=session)\n",
    "    for i, seq in enumerate(dense_decoded):\n",
    "        seq = ' '.join([str(s) for s in seq if s != -1])\n",
    "        print('\\t%d %s --> [%s]' % (i, Y[i], seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6I4pmTgVs0t"
   },
   "source": [
    "A seguir, treinamos nossa RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMF3AozwVs0u",
    "outputId": "4cf8aca3-695c-42eb-ece5-b476c153cdac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0 [2 2 9 6] --> []\n",
      "\t1 [5 8 9 8 4] --> []\n",
      "\t2 [5 4 1 8 3] --> []\n",
      "\t3 [0 6 5 1 5 7] --> []\n",
      "\t4 [2 1 2 9 4] --> []\n",
      "\t5 [9 4 8 5] --> []\n",
      "\t6 [3 0 3 8 5] --> []\n",
      "\t7 [8 7 0 2 7] --> []\n",
      "\t8 [7 5 3 2 0 5 1] --> []\n",
      "\t9 [5 0 1 3] --> []\n",
      " 1/10, tr_cost = 15.349, tr_ler = 0.996\n",
      " 2/10, tr_cost = 13.392, tr_ler = 0.996\n",
      "\t0 [1 5 0 4 7] --> [5]\n",
      "\t1 [9 0 3 4 1] --> []\n",
      "\t2 [2 5 6 1 0 0 8 9] --> [5]\n",
      "\t3 [6 3 0 4 4] --> []\n",
      "\t4 [2 4 7 6 0] --> [7]\n",
      "\t5 [4 6 7 8 2 9 0] --> []\n",
      "\t6 [8 3 5 9 1 6] --> [5]\n",
      "\t7 [9 7 3 6 4 7] --> [7 7]\n",
      "\t8 [3 5 7 1 6] --> [5 7]\n",
      "\t9 [8 1 8 5 4] --> [7 5]\n",
      " 3/10, tr_cost = 12.598, tr_ler = 0.929\n",
      " 4/10, tr_cost = 11.125, tr_ler = 0.830\n",
      "\t0 [9 5] --> [3 5 5]\n",
      "\t1 [8 7 2 6] --> [8 7 8 6]\n",
      "\t2 [4 0 4 7] --> [4 0 4 7]\n",
      "\t3 [5 1 6 3] --> [5 6 3]\n",
      "\t4 [7 3 1 9] --> [7 3 1 3]\n",
      "\t5 [8 3 4 2] --> [3 3 8]\n",
      "\t6 [0 4 8 9 5] --> [0 8 3 5]\n",
      "\t7 [0 3 8 6] --> [0 3 8 6]\n",
      "\t8 [0 7 5 4] --> [0 7 5 4]\n",
      "\t9 [5 1 8 7 3 9 6 2] --> [5 1 8 7 3 3 6 8]\n",
      " 5/10, tr_cost = 8.483, tr_ler = 0.602\n",
      " 6/10, tr_cost = 4.776, tr_ler = 0.278\n",
      "\t0 [5 0 3 1 5] --> [5 0 3 1 5]\n",
      "\t1 [8 4] --> [8 4]\n",
      "\t2 [3 4 0] --> [3 9 0]\n",
      "\t3 [0 7 3 4 6] --> [0 7 3 4 6]\n",
      "\t4 [9 1 0 8 3] --> [9 1 0 2 3]\n",
      "\t5 [6 0 8 1 6] --> [6 0 3 1 6]\n",
      "\t6 [7 3] --> [7 3]\n",
      "\t7 [3 2 1 0] --> [3 2 1 0]\n",
      "\t8 [5 4 9 7 5] --> [5 2 9 7 5]\n",
      "\t9 [3 0 3 8 5] --> [3 0 3 8 5]\n",
      " 7/10, tr_cost = 3.426, tr_ler = 0.208\n",
      " 8/10, tr_cost = 2.448, tr_ler = 0.138\n",
      "\t0 [8 9 1 2 4 0] --> [8 8 1 2 4 0]\n",
      "\t1 [9 4 2 3] --> [9 4 2 3]\n",
      "\t2 [1 9 0 2 8 3 4] --> [1 9 0 2 8 3 2]\n",
      "\t3 [5 0 9 2 5 8 6] --> [5 0 9 2 5 8 6]\n",
      "\t4 [3 6 7 2 1] --> [3 6 7 2 1]\n",
      "\t5 [7 9 8 6 5] --> [7 9 8 6 5]\n",
      "\t6 [2 4 1 6] --> [2 2 1 6]\n",
      "\t7 [2 8 0 5 7] --> [2 8 0 5 7]\n",
      "\t8 [2 3 0 8 5] --> [2 3 0 8 5]\n",
      "\t9 [4 3 0 4 6 3 2] --> [4 3 0 4 6 3 2]\n",
      " 9/10, tr_cost = 2.200, tr_ler = 0.112\n",
      "10/10, tr_cost = 0.882, tr_ler = 0.029\n"
     ]
    }
   ],
   "source": [
    "# You can preprocess the input data here\n",
    "Xtrain = input_seqs\n",
    "Ytrain = seq_labels\n",
    "\n",
    "batch_size = 5\n",
    "num_epochs = 10\n",
    "num_batches_per_epoch = int(num_examples/batch_size)\n",
    "\n",
    "# random cases to evaluate\n",
    "cases_to_show = np.random.randint(0, num_examples - 1, (10,))\n",
    "\n",
    "with tf.Session() as s:\n",
    "    # Initializate the weights and biases\n",
    "    init.run()\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "        train_cost = train_ler = 0\n",
    "        for batch in range(num_batches_per_epoch):\n",
    "\n",
    "            # Getting the index\n",
    "            indexes = [i % num_examples \n",
    "                       for i in range(batch * batch_size, (batch + 1) * batch_size)]\n",
    "            Xtrain_b = Xtrain[indexes]\n",
    "            \n",
    "            # Padding input to max_time_step of this batch\n",
    "            Xtrain_b, seqlen_train_b = pad_sequences(Xtrain_b)\n",
    "\n",
    "            # Converting to sparse representation so as to to feed SparseTensor input\n",
    "            Ytrain_b = sparse_tuple_from(Ytrain[indexes])\n",
    "\n",
    "            feed = {inputs: Xtrain_b,\n",
    "                    targets: Ytrain_b,\n",
    "                    seq_len: seqlen_train_b}\n",
    "            batch_cost, _ = s.run([cost, optimizer], feed_dict = feed)\n",
    "            train_cost += batch_cost*batch_size\n",
    "            train_ler += s.run(ler, feed_dict=feed)*batch_size\n",
    "\n",
    "        if e % 2 == 0:\n",
    "            show_decoded_seqs(s, Xtrain[cases_to_show], \n",
    "                              Ytrain[cases_to_show])        \n",
    "            \n",
    "        # Shuffle the data\n",
    "        shuffled_indexes = np.random.permutation(num_examples)\n",
    "        Xtrain = Xtrain[shuffled_indexes]\n",
    "        Ytrain = Ytrain[shuffled_indexes]\n",
    "\n",
    "        # Metrics mean\n",
    "        train_cost /= num_examples\n",
    "        train_ler /= num_examples\n",
    "\n",
    "        log = \"%2d/%2d, tr_cost = %.3f, tr_ler = %.3f\"\n",
    "        print(log % (e+1, num_epochs, train_cost, train_ler))\n",
    "    \n",
    "    saver.save(s, \"/tmp/ctc_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hu0Fu7rhVs0x"
   },
   "source": [
    "Finalmente, testamos em nossa coleção separada de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqsaYABIVs0x",
    "outputId": "c195bf8f-664a-4136-8831-15742b0265d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/ctc_model\n",
      "Evaluation on test set. Error: 0.03181349\n",
      "\t0 [4 2 4 6 2 8] --> [4 8 4 6 2 8]\n",
      "\t1 [5 4 1 3 9 7] --> [5 1 3 9 7]\n",
      "\t2 [6 2 4 1 7] --> [6 2 4 1 7]\n",
      "\t3 [3 1 3 8 0] --> [3 1 3 8 0]\n",
      "\t4 [7 8 6 0 9 2 5] --> [7 8 6 0 9 2 5]\n",
      "\t5 [1 2 7 8 3 5] --> [2 7 8 3 5]\n",
      "\t6 [3 9 0 4] --> [3 9 0 4]\n",
      "\t7 [1 2 7 8 3 5] --> [2 7 8 3 5]\n",
      "\t8 [8 6 9 5 7 2] --> [8 6 9 5 7 2]\n",
      "\t9 [3 9 0 4] --> [3 9 0 4]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "ftest = 'data/test_varlen.pkl'\n",
    "Xtest, Ytest, num_instances = get_toy_data(ftest)\n",
    "# Padding input to max_time_step of this batch\n",
    "Xtest_p, seqlen_test_p = pad_sequences(Xtest)\n",
    "# Converting to sparse representation so as to to feed SparseTensor input\n",
    "Ytest_s = sparse_tuple_from(Ytest)\n",
    "# test cases\n",
    "cases_to_show = np.random.randint(0, num_instances - 1, (10,))\n",
    "\n",
    "with tf.Session() as s:\n",
    "    saver.restore(s, \"/tmp/ctc_model\")\n",
    "    test_ler = s.run(ler, feed_dict={inputs: Xtest_p,\n",
    "                                     targets: Ytest_s,\n",
    "                                     seq_len: seqlen_test_p})\n",
    "    print ('Evaluation on test set. Error:', test_ler)\n",
    "    show_decoded_seqs(s, Xtest[cases_to_show], \n",
    "                      Ytest[cases_to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PiBsoAcVs00"
   },
   "source": [
    "Para todos considerando seriamente a função CTC, aconselho a usar a implementação do Baidu, disponibilizada publicamente em https://github.com/baidu-research/warp-ctc e compatível com tensorflow. Ela é usada nos sistemas de reconhecimento de fala do Baidu e é muito mais eficiente que a implementação original do tensorflow para GPUs e CPUs, tanto em termos de tempo quanto estabilidade numérica (ao menos, em setembro de 2017). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "14Bum2CxVs00"
   },
   "source": [
    "Alternativas à função CTC incluem (a) combinar DNNs com HMMs, mas esta parece ser uma estratégia sendo lentamente substituída, (b) RNNs para transdução de sequências (o modelo de CTC com a inclusão de dependência entre saídas e modelagem de transição de sequências, em outras palavras, um modelo de linguagem -- ver https://arxiv.org/pdf/1211.3711.pdf) e (c) uso de modelos de atenção que incluem no modelo neural o objetivo de aprender a 'olhar' para os 'segmentos' (https://arxiv.org/pdf/1506.07503v1.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1OkIoxTVs01"
   },
   "source": [
    "Esta aula foi baseada nos exemplos de Igor Macedo Quintanilha (https://github.com/igormq/ctc_tensorflow_example) e na explicação sobre CTC de Karl N. (https://gab41.lab41.org/speech-recognition-you-down-with-ctc-8d3b558943f0), além de usar dados criados pelo gerador sintético de Rakeshvar https://github.com/rakeshvar/rnn_ctc."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "3.1-LSTM-CTC.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
