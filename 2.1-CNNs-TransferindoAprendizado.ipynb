{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando Redes Pré-treinadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta aula, vamos ver como resolver problemas de classificação, quando temos poucos dados. Esta é uma situação muito comum, de fato. Neste caso, podemos usar os pesos aprendidos em uma rede complexa como ponto inicial de nosso treino. Este é um tipo especial de refinamento com redes neurais conhecido como _transferência de aprendizagem_ (TA).\n",
    "\n",
    "Nesta aula, em particular, vamos usar um dos modelos pré-treinados já disponibilizados pelo Keras, a InceptionV3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre os vários modelos disponíveis em keras.applications, vamos usar a Inception V3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import keras.applications.inception_v3 as iv3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar ter que baixar o modelo pela Internet, vamos modificar os paths originais usados na implementação do Keras. No lugar deles, vamos usar cópias dos modelos na rede local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iv3.WEIGHTS_PATH)\n",
    "print(iv3.WEIGHTS_PATH_NO_TOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iv3.WEIGHTS_PATH = 'http://papaleguas.icomp.ufam.edu.br/~marco/downloads/inception_v3_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "iv3.WEIGHTS_PATH_NO_TOP = 'http://papaleguas.icomp.ufam.edu.br/~marco/downloads/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "iv3.WEIGHTS_PATH = 'data/inception_v3_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "iv3.WEIGHTS_PATH_NO_TOP = 'data/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the base pre-trained model -- requires h5py package (pip install h5py, if necessary)\n",
    "base_model = iv3.InceptionV3(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed = 42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "def plot_colorfigs(lst, max_cols = 5):\n",
    "    'Exibe figuras coloridas em lista lst.'\n",
    "    if len(lst) == 1:\n",
    "        plt.imshow(lst[0], interpolation = 'nearest')\n",
    "        plt.axis = 'off'\n",
    "    else:\n",
    "        chunks = [lst[c:c+max_cols] for c in range(0, len(lst), max_cols)]\n",
    "        for ch in chunks:\n",
    "            f, axes = plt.subplots(1, len(ch))\n",
    "            for i, a in enumerate(axes):\n",
    "                a.imshow(ch[i], interpolation = 'nearest')\n",
    "                a.set(aspect = 'equal')\n",
    "                a.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distinguindo cães de gatos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta aula, vamos usar uma coleção de imagens de cães e gatos. A coleção original tem 25 mil fotos. Destas, vamos usar 1000 fotos de cães e 1000 de gatos como conjunto de treino, além de 400 fotos de cada espécie, como validação. \n",
    "\n",
    "Esta coleção (a original) tem uma importância histórica, uma vez que uma pesquisa feita há muitos anos com especialistas em visão indicava \"que qualquer acurácia acima de 60% não poderia vir sem algum grande avanço no estado da arte\" (cf. https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html). Por volta de 2014, com o uso de redes de convolução, atingiu-se uma acurácia de 80%, o estado-da-arte de então."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Linux rode isso\n",
    "\n",
    "dogs_cats = !find data/dogs_and_cats -name '*.jpg'\n",
    "dogs_cats[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Windows, o find nao funcionou no Anaconda, entao use isso\n",
    "\n",
    "with open(\"dogsandcats.txt\") as f:\n",
    "    dogs_cats = [l.rstrip('\\n') for l in f]\n",
    "    \n",
    "dogs_cats[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, temos um exemplo aleatório de imagem nessa coleção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uma imagem para classificar\n",
    "import random\n",
    "img_path = dogs_cats[random.randint(0, len(dogs_cats)-1)]\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "plot_colorfigs([img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificando Imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, usamos a rede InceptionV3 para classificar essa imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0) # insert a new dimension to x\n",
    "\n",
    "# pre-preccess intput to be compatible with InceptionV3 images\n",
    "x = iv3.preprocess_input(x)\n",
    "\n",
    "preds = base_model.predict(x)\n",
    "print('Class:', iv3.decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraindo features de camadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra tarefa comum com uma rede pré-treinada é extrair features de alguma das suas camadas (obter uma representação da entrada naquela camada). A seguir listamos todas as camadas na Inception V3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vendo camadas\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from avg_pool layer:\n",
    "model_at_layer = Model(inputs=base_model.input, \n",
    "                       outputs=base_model.get_layer('avg_pool').output)\n",
    "\n",
    "# process image\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "x = iv3.preprocess_input(x)\n",
    "\n",
    "# get features\n",
    "features = model_at_layer.predict(x)\n",
    "print('Features:', features.shape, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos verficar a qualidade da representação, para confirmar que a rede fornece representações similares para imagens de conteúdo similar. Para isso, vamos obter as features de 100 imagens aleatórias de nossa coleção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtendo os vizinhos mais proximos de 100 figuras aleatorias\n",
    "dogs_cats100 = random.sample(dogs_cats, 100)\n",
    "\n",
    "features = []\n",
    "for img_path in dogs_cats100:\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = iv3.preprocess_input(x)\n",
    "    features += [model_at_layer.predict(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que nesta camada, as representações tem 2048 dimensões. Vamos indexá-las para ser possível usar um algoritmo de vizinhança. Para tanto, vamos mudar a dimensão de cada representação para ser um vetor linha em vez de um vetor coluna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(features)):\n",
    "    features[i] = features[i].reshape((2048,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "neigh = NearestNeighbors(2)\n",
    "neigh.fit(features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos obter as imagens mais similares a qualquer uma tomada aleatoriamente. Como esperado, os vizinhos mais próximos são normalmente imagens de conteúdo similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rquery = random.randint(0, 99)\n",
    "indices = neigh.kneighbors([features[rquery]], 3, return_distance=False)\n",
    "plot_colorfigs([image.load_img(dogs_cats100[i], target_size=(299, 299)) for i in indices[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vendo ativações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uma imagem de teste\n",
    "img_path = dogs_cats[6]\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "plot_colorfigs([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in base_model.layers[:30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_model = Model(inputs = base_model.inputs, outputs = layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0) \n",
    "x = iv3.preprocess_input(x)\n",
    "acts = act_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lacts = acts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lacts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layermaps = [lacts[0, :, :, m] for m in range(lacts.shape[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_colorfigs(layermaps, max_cols = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreinando Inception v3 para um novo conjunto de classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos treinar a rede para prever _gatos x cães_ em lugar das 1000 classes da Imaginet. Para tanto, vamos ler de novo a InceptionV3, desta vez sem as camadas do topo (o classificador no topo da rede de convolução)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tamanho das imagens\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/dogs_and_cats/train' \n",
    "validation_data_dir = 'data/dogs_and_cats/validation' \n",
    "\n",
    "# criando o modelo base pre treinado\n",
    "base_model = iv3.InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adicione uma rede de classificação no topo da Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No topo da nossa rede, vamos colocar uma rede totalmente conectada para classificar as imagens. Para isso vamos transformar as features de saída da InceptionV3 em 1024 entradas para uma rede softmax.\n",
    " - Global Average Pooling é uma técnica de pooling onde cada mapa da convolução é transformado em um único valor, que é a média de todos os valores do mapa. Ou seja, ele transforma um tensor _Altura x Largura x Mapas_ para um 1x1xMapas, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congele todas as camadas, exceto as que foram adicionadas agora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas as camadas da InceptionV3 serão congeladas de forma que os seus pesos não serão modificados no treino. Apenas os pesos da nossa rede de topo serão modificados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare os conjuntos de treino e teste, gerando novas imagens se possível"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta fase, vamos gerar os conjuntos de treino e teste. Note que é uma boa oportunidade para gerar casos de treino com ruído para tornar a rede mais robusta. \n",
    "\n",
    "Esta técnica é chamada de _data augmentation_ e pode ser feita pelo Keras usando a classe _ImageDataGenerator_. Abaixo, temos exemplos de transformações que podem ser realizadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from PIL import Image\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,       # image rotation (degrees)\n",
    "        width_shift_range=0.2,   # width-% range for image translation \n",
    "        height_shift_range=0.2,  # height-% range for image translation \n",
    "        shear_range=0.2,         # cf https://en.wikipedia.org/wiki/Shear_mapping\n",
    "        zoom_range=0.2,          # zoom\n",
    "        horizontal_flip=True,    # mirroring effect\n",
    "        fill_mode='nearest')     # how to fill gaps resulting from other transformations\n",
    "\n",
    "img = load_img(dogs_cats[random.randint(0, len(dogs_cats)-1)])\n",
    "x = img_to_array(img)\n",
    "\n",
    "figs = [img]\n",
    "figs += [array_to_img(datagen.random_transform(x)) for i in range(3)]\n",
    "plot_colorfigs(figs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o método ImageDataGenerator.flow() pode ser usado para gerar continuamente batches de imagens transformadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255)#,\n",
    "#        rotation_range=40,\n",
    "#        width_shift_range=0.2,\n",
    "#        height_shift_range=0.2,\n",
    "#        shear_range=0.2,\n",
    "#        zoom_range=0.2,\n",
    "#        horizontal_flip=True,\n",
    "#        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treine o novo modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O novo modelo pode ser então treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start history model\")\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50, # 50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('/tmp/first_try_top.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agora refine a rede global, treinando uma parte da Inception original junto com as novas camadas adicionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao fim do processo anterior, já temos o topo da nossa rede de convolução treinada para o problema de discriminação entre cães e gatos. Podemos, agora, refinar o modelos retreinando algumas camadas de convolução da rede. Assim, vamos congelar as N camadas mais do fundo e deixar treinar as camadas mais perto do topo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('/tmp/first_try_conv.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E agora temos a rede treinada. \n",
    "\n",
    "Da forma como fizemos, ela não vai alcançar um grande resultado. Mas com a inclusão de mais imagens por _data augmentation_, uso de regularizadores junto com o descongelamento de mais algumas camadas, é possível atingir uma precisão em torno de 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo sobre transferência de aprendizagem\n",
    "\n",
    "Entre os vários fatores importantes para TA, dois a considerar são o tamanho da base a treinar (base nova -- BN) e a similaridade com a base treinada (base original -- BO). Supondo que as duas bases foram criadas para tarefas similares (ex: classificação de imagens naturais), temos quatro cenários:\n",
    "\n",
    "* __BO >> BN com conteudo similar__: se a BN é pequena, o _tuning_ de parâmetros pode levar a _overfitting_. Como elas são similares, os atributos de alto nível da BO servem para a BN. Logo, é melhor treinar um classificador linear nos atributos (de alto nível) aprendidos pela BO. Em suma, _use_ CNN(BO) _como codificador para_ BN.\n",
    "\n",
    "* __BO $\\gtrsim$ BN com conteúdo similar__: comece com pesos da BO e depois de treinar BN, faça tuning dos parâmetros. Fizemos isso nesta aula. Note que, em particular, isso não foi um grande problema nesta aula porque a nossa BN é sobre um conteúdo (cães x gatos) coberto, de certa forma, pela BO, já que a Imagenet inclui raças de cães e gatos entre seus alvos.\n",
    "\n",
    "* __BO >> BN com conteúdo distinto__: treine um classificador linear usando atributos de baixo nível da BO.\n",
    "\n",
    "* __BO $\\gtrsim$ BN com conteúdo distinto__: use os pesos aprendidos para BO (partir de uma rede pre-treinada pode ser sempre útil), treine uma CNN para BN e faça tuning de todos os parâmetros da arquitetura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Esta aula foi baseada no livro de François Chollet e na sua aula disponível em https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html; também foi usado material de Edward Tufte, disponível em http://blog.revolutionanalytics.com/2016/08/deep-learning-part-2.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
