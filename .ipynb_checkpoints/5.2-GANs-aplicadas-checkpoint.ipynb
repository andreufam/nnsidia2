{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicações de GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ampliando treino supervisionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Augmented Simplification Network__: rede neural usada para simplificar skecthes gerando versão vetorizada, treinada com exemplos gerados por GAN. A GAN é usada para obter mais exemplos de desenho à lápis, de forma a aumentar treino para rede simplificadora, que sejam mais similares a desenhos feitos à mão por seres humanos em termos de diversidade (http://hi.cs.waseda.ac.jp/~esimo/publications/SimoSerraARXIV2017.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/sketches_model.png\" alt=\"sketches\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir temos exemplos de imagens \"desenhadas à lápis\" gerada por GAN apartir de sketches digitais:\n",
    "\n",
    "<img src=\"images/sketches_generated.png\" alt=\"sketches\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo temos dois sketches reais e as versões vetorizadas deles obtida pela rede de simplificação treinada sem e com exemplos gerados pela GAN:\n",
    "\n",
    "<img src=\"images/sketches_results.png\" alt=\"sketches\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração de personagens de Anime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__IllustrationGAN__: DCGAN com vários truques. Na imagem abaixo, a primeira linha corresponde a personagens gerados pela GAN e as linhas seguintes correspondem aos 5 vizinhos mais próximos no treino. Como observado, embora a GAN imagine imagens parecidas com as do treino, elas nunca são exatamente iguais (https://github.com/tdrussell/IllustrationGAN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/illustration_gan_train_knn.png\" alt=\"IllustrationGAN\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração de fontes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__zi2zi__: aprendendo caligrafia chinesa com GANs. A ideia é copiar o estilo de um fonte, baseado em uma amostra, para novos exemplos de caracteres não desenhados naquele fonte. Por Yuchen Tian (https://kaonashi-tyc.github.io/2017/04/06/zi2zi.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/tiangan.png\" alt=\"Tiangan\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/tianfonts.gif\" alt=\"ChineseFonts\" style=\"width: 350px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração interativa de imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__iGAN__: gera imagens com base em entradas do usuário. Por Jun-Yan Zhu (https://github.com/junyanz/iGAN, https://arxiv.org/pdf/1609.03552v2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/igandemo.gif\" alt=\"iGAN\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__iDeepColor__: ferramenta interativa para colorir fotos naturais em escala de cinza. Usuário precisa apenas indicar a cor de certos pontos na imagem e ela é propagada corretamente. Cores não informadas são estimadas de acordo com sua plasabilidade. A ferramenta também sugere opções de cor para os pontos que o usuário indica, garantindo plausabilidade e diversidade (https://richzhang.github.io/ideepcolor/)\n",
    "\n",
    "<img src=\"images/deepcolor.png\" alt=\"iGAN\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração de imagens a partir de texto\n",
    "\n",
    "Há toda uma linha de pesquisa aqui. Escolhemos como exemplo um artigo que introduz um novo elemento no problema: a posição espacial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Learning what and where to draw__: gera imagens com base em texto e diversas informações espaciais. No exemplo abaixo, usa uma caixa para indicar onde o elemento solicitado deve ser gerado (https://github.com/reedscot/nips2016, http://www.scottreed.info/files/nips2016.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/keypoint_network.jpg\" alt=\"iGAN\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cub_move_bbox.jpg\" alt=\"ImageFromText\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edição de imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Invertible Conditional GANs__: imagem é aprendida com atributos, cuja mudança permite a criação de novas imagens (https://github.com/Guim3/IcGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/icgan_model.png\" alt=\"icGAN\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/icgan_examples.png\" alt=\"icGAN\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Envelhecimento/Rejuvenescimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Age Regression/Progression Conditional Adversarial Autoencoder__: imagens de diferentes idades e personalidades são representadas em espaço, de forma que travessia do espaço permite passear por diferentes idades e personalidades (https://github.com/ZZUTK/Face-Aging-CAAE, http://web.eecs.utk.edu/~zzhang61/docs/papers/2017_CVPR_Age.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/agemodel.png\" alt=\"icGAN\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ageexamples.png\" alt=\"icGAN\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transferência de domínio\n",
    "\n",
    "Há muitas aplicaçõees nesta linha... vou citar apenas três bem interessantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__pix2pix__: tradução de imagem para imagem. Rede usa uma GAN condicional treinada com pares de imagens que representam a transferência de domínio desejada. Discriminador tem que determinar se imagem gerada é o par verdadeiro ou falso (https://github.com/phillipi/pix2pix). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/pix2pix.jpg\" alt=\"pix2pix\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CycleGAN__: pix2pix _sem_ usar pares de imagens para treino. Aqui é usada uma GAN cíclica deve gera imagem alvo (ex: zebra) de imagem original e, então, tenta obter a imagem original da imagem gerada. Ao fazer isso, ela cria pares (https://junyanz.github.io/CycleGAN/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cycle_model1.jpg\" alt=\"cycle1\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cycle_model2.jpg\" alt=\"cycle1\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/horse2zebra.gif\" alt=\"horse2zebra\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cyclegan2.jpeg\" alt=\"cycle1\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LookBook__: tradução de imagem para imagem em nível de pixel. No exemplo abaixo, fotos de modelos são transformadas em suas roupas (https://github.com/fxia22/PixelDTGAN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lookgan_model.png\" alt=\"pix2pix\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lookgan.jpg\" alt=\"pix2pix\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completar Imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generative Face Completion__: rede com um gerador e dois discriminadores, um para a face completa e outro apenas para a parte gerada. Uma rede parser pré-treinada é ainda usada para adicionar consistência ao modelo (https://github.com/Yijunmaverick/GenerativeFaceCompletion). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/facecompletion_model.png\" alt=\"pix2pix\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/facecompletion.png\" alt=\"pix2pix\" style=\"width: 400px;\"/>\n",
    "<img src=\"images/facecompletion2.png\" alt=\"pix2pix\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhorar resolução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__srez__: converte imagem de baixa resolução em hopótese de alta resolução. Basicamente, DCGAN com módulos ResNet e função discriminativa que tenta tanto forçar imagens plasíveis (via GAN) quanto similares à entrada (via regularizador L1) (https://github.com/david-gpu/srez). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo, vemos a imagem original em baixa resolução seguida do resultado de um baseline, da saída da srez e da imagem real, em alta resolução.\n",
    "\n",
    "<img src=\"images/srez_sample_output.png\" alt=\"srez\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SRGAN__: converte imagem de baixa resolução em hopótese de alta resolução. Como a anterior, GAN força imagens plausíveis enquanto uma segunda função de perda se concentra em similaridade perceptual em lugar de similaridade de pixels (https://arxiv.org/pdf/1609.04802.pdf, https://github.com/titu1994/Super-Resolution-using-Generative-Adversarial-Networks). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/srgan_model.png\" alt=\"srez\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo abaixo, a imagem em baixa resolução a ser melhorada, o resultado obtido por uma ResNet, o resultado da SRGAN e a imagem original, em alta resolução:\n",
    "\n",
    "<img src=\"images/srgan_examples.png\" alt=\"srez\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos exemplos abaixo, a mesma técnica usada para expandir imagem original e melhorar resolução de vídeo:\n",
    "\n",
    "<img src=\"images/srgan-examples2.jpg\" alt=\"srgan\" style=\"width: 800px;\"/>\n",
    "<img src=\"images/srgan_examples3.jpg\" alt=\"srgan\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__GP-GAN__: combina duas imagens usando GAN e um modelo de Poisson para representar a área de blending (https://github.com/wuhuikai/GP-GAN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/gpgan_model.png\" alt=\"gpgan\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/gpgan-example.png\" alt=\"gpgan\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsão de próximo frame em vídeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adversarial Video Generation__: método para melhorar qualidade e coerência de previsão do próximo frame de um vídeo, baseado nos últimos quatro frames. Usa uma rede de convolução multi-escalar (https://github.com/dyelax/Adversarial_Video_Generation, https://arxiv.org/abs/1511.05440). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/pacman.gif\" alt=\"video\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento de Linguagem Natural\n",
    "\n",
    "Na prática, GANs são díficeis de treinar e o problema é mais díficil ainda  quando aplicado a problemas discretos como PLN. Nestes casos, em lugar de uma CNN, temos que usar RNNs que são mais díficeis de treinar. Apesar disso, há alguma coisa na literatura recente, embora não tão espetacular quanto o que vemos com imagens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Machine Translation__: métodos para melhorar qualidade da tradução de linguagen natural (https://github.com/ngohoanhkhoa/GAN-NMT, https://arxiv.org/abs/1704.06933). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/translationgan.png\" alt=\"video\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseado no blog de Minchul Shin, http://blog.peimin.org/?p=809; e Yaron hadad http://www.yaronhadad.com/deep-learning-most-amazing-applications/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
